{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*UkI9za9zTR-HL8uM15Wmzw.png\"/>"
      ],
      "text/plain": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*UkI9za9zTR-HL8uM15Wmzw.png\"/>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*UkI9za9zTR-HL8uM15Wmzw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height has been deprecated.\n\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.height', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copying the dataframe so I have a before and after\n",
    "df = pd.read_csv('c:/Users/Franz Lom/Documents/TensorFlow/gesture_recognition/Data/extracted_data/cir_hor_cclk.csv') # saving circle horizontal counter clockwise csv as df\n",
    "dataframe = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tester', 'trial', 'rightHanded', 'timestamp', 'posX', 'posY', 'posZ', 'posRelX', 'posRelY', 'posRelZ', 'velX', 'velY', 'velZ', 'quatW', 'quatX', 'quatY', 'quatZ', 'accRelX', 'accRelY', 'accRelZ', 'accAbsX', 'accAbsY', 'accAbsZ']\n"
     ]
    }
   ],
   "source": [
    "# this is the headers for all the columns within the file\n",
    "print(list(dataframe)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this displays up to when the person switches (when tester changes)\n",
    "# trial number is the attepmt of a circle\n",
    "# time stamp displays the duration\n",
    "# poxX is an arbitrary pos(vec) \n",
    "\n",
    "#print(dataframe[['tester','trial','timestamp', 'posX']].head(590))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access to some of the columns within the dataframe\n",
    "\n",
    "tester = [x for x in dataframe['tester']]\n",
    "trial = [x for x in dataframe['trial']]\n",
    "timestamp = [x for x in dataframe['timestamp']]  # not unix timestamp - seconds\n",
    "posX = [x for x in dataframe['posX']]\n",
    "posY = [x for x in dataframe['posY']]\n",
    "posZ = [x for x in dataframe['posZ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter:  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  1\n1\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  2\n2\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  3\n3\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n4\nrow trial  4\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(dataframe['trial'].unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "plt.scatter(dataframe['timestamp'], dataframe['posZ'], s=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-1120702c186c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# we need to split the data to training data and testing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmsk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmsk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmsk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# we need to split the data to training data and testing data\n",
    "\n",
    "msk = np.random.rand(len(m)) < 0.9\n",
    "train = m[msk]\n",
    "test = m[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([(1, 'B1'), (2, 'B1'), (3, 'B1'), (4, 'B1'), (5, 'B1'), (6, 'B1'), (7, 'B1'), (8, 'B1'), (9, 'B1'), (10, 'B1'), (1, 'B2'), (2, 'B2'), (3, 'B2'), (4, 'B2'), (5, 'B2'), (6, 'B2'), (7, 'B2'), (8, 'B2'), (9, 'B2'), (10, 'B2'), (1, 'C1'), (2, 'C1'), (3, 'C1'), (4, 'C1'), (5, 'C1'), (6, 'C1'), (7, 'C1'), (8, 'C1'), (9, 'C1'), (10, 'C1'), (1, 'C2'), (2, 'C2'), (3, 'C2'), (4, 'C2'), (5, 'C2'), (6, 'C2'), (7, 'C2'), (8, 'C2'), (9, 'C2'), (10, 'C2'), (1, 'D1'), (2, 'D1'), (3, 'D1'), (4, 'D1'), (5, 'D1'), (6, 'D1'), (7, 'D1'), (8, 'D1'), (9, 'D1'), (10, 'D1'), (1, 'D2'), (2, 'D2'), (3, 'D2'), (4, 'D2'), (5, 'D2'), (6, 'D2'), (7, 'D2'), (8, 'D2'), (9, 'D2'), (10, 'D2'), (1, 'F1'), (2, 'F1'), (3, 'F1'), (4, 'F1'), (5, 'F1'), (6, 'F1'), (7, 'F1'), (8, 'F1'), (9, 'F1'), (10, 'F1'), (1, 'J1'), (2, 'J1'), (3, 'J1'), (4, 'J1'), (5, 'J1'), (6, 'J1'), (7, 'J1'), (8, 'J1'), (9, 'J1'), (10, 'J1'), (1, 'J2'), (2, 'J2'), (3, 'J2'), (4, 'J2'), (5, 'J2'), (6, 'J2'), (7, 'J2'), (8, 'J2'), (9, 'J2'), (10, 'J2'), (1, 'J3'), (2, 'J3'), (3, 'J3'), (4, 'J3'), (5, 'J3'), (6, 'J3'), (7, 'J3'), (8, 'J3'), (9, 'J3'), (10, 'J3'), (1, 'J4'), (2, 'J4'), (3, 'J4'), (4, 'J4'), (5, 'J4'), (6, 'J4'), (7, 'J4'), (8, 'J4'), (9, 'J4'), (10, 'J4'), (1, 'J5'), (2, 'J5'), (3, 'J5'), (4, 'J5'), (5, 'J5'), (6, 'J5'), (7, 'J5'), (8, 'J5'), (9, 'J5'), (10, 'J5'), (1, 'M1'), (2, 'M1'), (3, 'M1'), (4, 'M1'), (5, 'M1'), (6, 'M1'), (7, 'M1'), (8, 'M1'), (9, 'M1'), (10, 'M1'), (1, 'M2'), (2, 'M2'), (3, 'M2'), (4, 'M2'), (5, 'M2'), (6, 'M2'), (7, 'M2'), (8, 'M2'), (9, 'M2'), (10, 'M2'), (1, 'M3'), (2, 'M3'), (3, 'M3'), (4, 'M3'), (5, 'M3'), (6, 'M3'), (7, 'M3'), (8, 'M3'), (9, 'M3'), (10, 'M3'), (1, 'R1'), (2, 'R1'), (3, 'R1'), (4, 'R1'), (5, 'R1'), (6, 'R1'), (7, 'R1'), (8, 'R1'), (9, 'R1'), (10, 'R1'), (1, 'R2'), (2, 'R2'), (3, 'R2'), (4, 'R2'), (5, 'R2'), (6, 'R2'), (7, 'R2'), (8, 'R2'), (9, 'R2'), (10, 'R2'), (1, 'S1'), (2, 'S1'), (3, 'S1'), (4, 'S1'), (5, 'S1'), (6, 'S1'), (7, 'S1'), (8, 'S1'), (9, 'S1'), (10, 'S1'), (1, 'S2'), (2, 'S2'), (3, 'S2'), (4, 'S2'), (5, 'S2'), (6, 'S2'), (7, 'S2'), (8, 'S2'), (9, 'S2'), (10, 'S2'), (1, 'S3'), (2, 'S3'), (3, 'S3'), (4, 'S3'), (5, 'S3'), (6, 'S3'), (7, 'S3'), (8, 'S3'), (9, 'S3'), (10, 'S3'), (1, 'T1'), (2, 'T1'), (3, 'T1'), (4, 'T1'), (5, 'T1'), (6, 'T1'), (7, 'T1'), (8, 'T1'), (9, 'T1'), (10, 'T1'), (1, 'T2'), (2, 'T2'), (3, 'T2'), (4, 'T2'), (5, 'T2'), (6, 'T2'), (7, 'T2'), (8, 'T2'), (9, 'T2'), (10, 'T2'), (1, 'U1'), (2, 'U1'), (3, 'U1'), (4, 'U1'), (5, 'U1'), (6, 'U1'), (7, 'U1'), (8, 'U1'), (9, 'U1'), (10, 'U1'), (1, 'W1'), (2, 'W1'), (3, 'W1'), (4, 'W1'), (5, 'W1'), (6, 'W1'), (7, 'W1'), (8, 'W1'), (9, 'W1'), (10, 'W1'), (1, 'W2'), (2, 'W2'), (3, 'W2'), (4, 'W2'), (5, 'W2'), (6, 'W2'), (7, 'W2'), (8, 'W2'), (9, 'W2'), (10, 'W2'), (1, 'Y1'), (2, 'Y1'), (3, 'Y1'), (4, 'Y1'), (5, 'Y1'), (6, 'Y1'), (7, 'Y1'), (8, 'Y1'), (9, 'Y1'), (10, 'Y1'), (1, 'Y2'), (2, 'Y2'), (3, 'Y2'), (4, 'Y2'), (5, 'Y2'), (6, 'Y2'), (7, 'Y2'), (8, 'Y2'), (9, 'Y2'), (10, 'Y2'), (1, 'Y3'), (2, 'Y3'), (3, 'Y3'), (4, 'Y3'), (5, 'Y3'), (6, 'Y3'), (7, 'Y3'), (8, 'Y3'), (9, 'Y3'), (10, 'Y3')]) \n\n280 \n\n      tester  trial rightHanded   timestamp      posX      posY      posZ   posRelX   posRelY   posRelZ      velX          velY      velZ     quatW     quatX     quatY     quatZ   accRelX   accRelY  accRelZ   accAbsX   accAbsY   accAbsZ\n22974     B2      1           L    16.66000  0.046176  0.276226 -0.464650  0.000000  0.000000  0.000000  0.000000  0.000000e+00  0.000000 -0.702897  0.708961  0.028066  0.050223 -0.041667  0.038462     0.96 -0.006658 -0.039619 -0.049389\n22975     B2      1           L    33.32500  0.046074  0.276587 -0.465288 -0.000102  0.000360 -0.000638 -0.000006  2.161540e-05 -0.000038 -0.703015  0.708776  0.026372  0.052079 -0.083333  0.000000     1.00 -0.046020  0.002293 -0.015358\n22976     B2      1           L    49.99500  0.045457  0.276681 -0.465823 -0.000719  0.000454 -0.001173 -0.000037  5.654752e-06 -0.000032 -0.703015  0.708776  0.026372  0.052079 -0.083333  0.000000     1.00 -0.046020  0.002293 -0.015358\n22977     B2      1           L    66.66600  0.045431  0.276679 -0.465889 -0.000745  0.000453 -0.001239 -0.000002 -1.144112e-07 -0.000004 -0.705571  0.706068  0.028408  0.053191 -0.083333  0.076923     1.00 -0.038842  0.002088 -0.084691\n22978     B2      1           L    83.33401  0.045204  0.276640 -0.466186 -0.000971  0.000414 -0.001536 -0.000014 -2.319030e-06 -0.000018 -0.705773  0.705807  0.028492  0.053943 -0.166667  0.115385     1.00 -0.116072  0.005092 -0.131945\n22979     B2      1           L   100.00300  0.044031  0.276621 -0.467819 -0.002144  0.000395 -0.003170 -0.000070 -1.147825e-06 -0.000098 -0.705881  0.705271  0.030153  0.058443 -0.166667  0.038462     1.00 -0.120548  0.005798 -0.055628\n22980     B2      1           L   116.67100  0.043771  0.276433 -0.467986 -0.002405  0.000206 -0.003336 -0.000016 -1.130908e-05 -0.000010 -0.705881  0.705271  0.030153  0.058443 -0.166667  0.038462     1.00 -0.120548  0.005798 -0.055628\n22981     B2      1           L   133.33800  0.042781  0.276837 -0.469208 -0.003395  0.000610 -0.004558 -0.000059  2.424131e-05 -0.000073 -0.701492  0.709037  0.032668  0.064099 -0.208333 -0.115385     1.00 -0.176835  0.009618  0.078212\n22982     B2      1           L   150.00800  0.042138  0.276817 -0.470323 -0.004037  0.000591 -0.005673 -0.000039 -1.158483e-06 -0.000067 -0.699122  0.710853  0.035607  0.068185 -0.250000 -0.192308     0.96 -0.229845 -0.026141  0.140895\n22983     B2      1           L   166.67900  0.039595  0.276719 -0.473156 -0.006581  0.000492 -0.008506 -0.000153 -5.918993e-06 -0.000170 -0.697881  0.711441  0.039428  0.072515 -0.250000 -0.192308     0.96 -0.230624 -0.025562  0.135519\n22984     B2      1           L   183.35900  0.036453  0.276665 -0.474754 -0.009723  0.000439 -0.010105 -0.000188 -3.226796e-06 -0.000096 -0.696812  0.711478  0.045775  0.078462 -0.250000 -0.192308     0.92 -0.235402 -0.065375  0.130173\n22985     B2      1           L   200.01300  0.033984  0.276621 -0.476795 -0.012191  0.000395 -0.012145 -0.000148 -2.639510e-06 -0.000123 -0.696234  0.711514  0.049063  0.081233 -0.291667 -0.269231     0.92 -0.292167 -0.061619  0.195022\n22986     B2      1           L   216.68400  0.031747  0.276729 -0.477728 -0.014429  0.000502 -0.013078 -0.000134  6.460659e-06 -0.000056 -0.694752  0.711566  0.057938  0.087389 -0.250000 -0.230769     0.96 -0.249446 -0.024916  0.156022\n22987     B2      1           L   233.35000  0.026647  0.276650 -0.477661 -0.019529  0.000423 -0.013012 -0.000306 -4.733393e-06  0.000004 -0.694113  0.711678  0.061012  0.089438 -0.208333 -0.230769     1.00 -0.209539  0.013343  0.160891\n22988     B2      1           L   250.02100  0.022670  0.276057 -0.477260 -0.023506 -0.000169 -0.012610 -0.000239 -3.554611e-05  0.000024 -0.692165  0.711904  0.070123  0.095829 -0.166667 -0.230769     1.00 -0.176252  0.011799  0.161957\n22989     B2      1           L   266.68900  0.015826  0.276280 -0.476019 -0.030350  0.000054 -0.011369 -0.000411  1.338493e-05  0.000074 -0.690886  0.711006  0.079976  0.103684 -0.125000 -0.230769     1.00 -0.143089  0.010240  0.166796\n22990     B2      1           L   283.36000  0.009658  0.275564 -0.475491 -0.036518 -0.000662 -0.010841 -0.000370 -4.295248e-05  0.000032 -0.690748  0.708305  0.090666  0.113804 -0.166667 -0.153846     1.00 -0.167595  0.008460  0.079789\n22991     B2      1           L   300.02600  0.001912  0.274828 -0.473538 -0.044264 -0.001398 -0.008888 -0.000465 -4.414560e-05  0.000117 -0.690148  0.706998  0.097531  0.119734 -0.166667 -0.153846     1.00 -0.170678  0.008147  0.077168\n22992     B2      1           L   316.69600 -0.006702  0.274787 -0.471547 -0.052878 -0.001440 -0.006897 -0.000517 -2.510043e-06  0.000119 -0.687361  0.707140  0.106830  0.126786 -0.125000 -0.192308     1.04 -0.146954  0.048281  0.117129\n22993     B2      1           L   333.36300 -0.015558  0.274564 -0.470000 -0.061734 -0.001663 -0.005350 -0.000531 -1.337502e-05  0.000093 -0.686123  0.707465  0.110059  0.128900 -0.083333 -0.192308     1.04 -0.109898  0.047505  0.127206\n22994     B2      1           L   350.02800 -0.024582  0.273761 -0.467359 -0.070758 -0.002466 -0.002709 -0.000542 -4.818441e-05  0.000158 -0.682816  0.707880  0.120113  0.135059  0.000000 -0.269231     1.04 -0.067172  0.049526  0.219247\n22995     B2      1           L   366.70300 -0.034642  0.273023 -0.463970 -0.080818 -0.003203  0.000679 -0.000603 -4.424151e-05  0.000203 -0.680824  0.706134  0.131306  0.143568  0.000000 -0.269231     1.00 -0.078594  0.009567  0.216983\n22996     B2      1           L   383.37100 -0.043691  0.272807 -0.460077 -0.089867 -0.003420  0.004573 -0.000543 -1.297010e-05  0.000234 -0.680025  0.704449  0.137806  0.149423 -0.083333 -0.230769     1.00 -0.145050  0.008598  0.147952\n22997     B2      1           L   400.03700 -0.055371  0.273220 -0.455605 -0.101546 -0.003006  0.009045 -0.000701  2.479535e-05  0.000268 -0.678387  0.703453  0.145257  0.154420  0.000000 -0.192308     1.00 -0.059417  0.006477  0.143025\n22998     B2      1           L   416.70700 -0.066380  0.273998 -0.449916 -0.112556 -0.002229  0.014734 -0.000660  4.665928e-05  0.000341 -0.675100  0.703970  0.153923  0.158029  0.041667 -0.230769     1.04 -0.046384  0.048738  0.185977\n22999     B2      1           L   433.39300 -0.077091  0.273701 -0.444537 -0.123267 -0.002525  0.020112 -0.000642 -1.777676e-05  0.000322 -0.670882  0.705939  0.161313  0.159829  0.083333 -0.192308     1.04 -0.000716  0.049018  0.158387\n23000     B2      1           L   450.04400 -0.089340  0.273588 -0.438633 -0.135516 -0.002639  0.026016 -0.000736 -6.819220e-06  0.000355 -0.668747  0.707136  0.164312  0.160426  0.125000 -0.269231     1.00 -0.001397  0.014618  0.242193\n23001     B2      1           L   466.71400 -0.101809  0.272931 -0.432776 -0.147985 -0.003295  0.031874 -0.000748 -3.939731e-05  0.000351 -0.664090  0.710080  0.170509  0.160306  0.208333 -0.346154     1.00  0.029184  0.024579  0.335575\n23002     B2      1           L   483.39700 -0.114633  0.272429 -0.425850 -0.160808 -0.003798  0.038800 -0.000769 -3.009526e-05  0.000415 -0.661953  0.710371  0.177803  0.159931  0.333333 -0.307692     1.04  0.143830  0.069443  0.350700\n23003     B2      1           L   500.04900 -0.127303  0.272556 -0.418219 -0.173479 -0.003671  0.046431 -0.000761  7.604505e-06  0.000458 -0.661915  0.709357  0.181691  0.160217  0.333333 -0.192308     1.00  0.190628  0.023610  0.252939\n23004     B2      1           L   516.71700 -0.139577  0.272501 -0.410628 -0.185753 -0.003725  0.054022 -0.000736 -3.264875e-06  0.000455 -0.661789  0.708725  0.185103  0.159627  0.208333 -0.153846     0.96  0.092585 -0.023548  0.163220\n23005     B2      1           L   533.38900 -0.151437  0.272624 -0.400840 -0.197613 -0.003602  0.063809 -0.000711  7.377291e-06  0.000587 -0.661789  0.708725  0.185103  0.159627  0.208333 -0.153846     0.96  0.092585 -0.023548  0.163220\n23006     B2      1           L   550.05600 -0.164111  0.272932 -0.389769 -0.210286 -0.003295  0.074880 -0.000760  1.846218e-05  0.000664 -0.661686  0.708339  0.191080  0.154647  0.375000 -0.076923     1.00  0.259329  0.025210  0.168033\n23007     B2      1           L   566.72500 -0.178487  0.272788 -0.377576 -0.224663 -0.003438  0.087073 -0.000862 -8.601530e-06  0.000731 -0.663755  0.706448  0.193313  0.151626  0.333333  0.000000     0.96  0.252396 -0.019469  0.086989\n23008     B2      1           L   583.39800 -0.188321  0.272749 -0.366179 -0.234497 -0.003477  0.098471 -0.000590 -2.330851e-06  0.000684 -0.664629  0.705797  0.193965  0.149989  0.333333  0.038462     0.96  0.267191 -0.020263  0.053989\n23009     B2      1           L   600.06300 -0.198577  0.272840 -0.354137 -0.244753 -0.003386  0.110513 -0.000615  5.422167e-06  0.000723 -0.666115  0.705333  0.195340  0.143662  0.416667  0.038462     0.96  0.330354 -0.010365  0.090440\n23010     B2      1           L   616.73400 -0.211027  0.272010 -0.339649 -0.257202 -0.004216  0.125001 -0.000747 -4.974752e-05  0.000869 -0.666617  0.707283  0.194952  0.131781  0.583333  0.038462     1.00  0.462592  0.051379  0.149556\n23011     B2      1           L   633.40410 -0.221438  0.271820 -0.327228 -0.267614 -0.004406  0.137422 -0.000625 -1.142032e-05  0.000745 -0.666953  0.707862  0.194529  0.127533  0.666667 -0.038462     1.04  0.495302  0.105112  0.246832\n23012     B2      1           L   650.06900 -0.231581  0.272001 -0.312575 -0.277757 -0.004226  0.152075 -0.000609  1.082828e-05  0.000879 -0.670113  0.707253  0.192388  0.117168  0.750000  0.038462     1.08  0.590916  0.157655  0.202566\n23013     B2      1           L   666.74100 -0.238708  0.271008 -0.300022 -0.284884 -0.005219  0.164628 -0.000427 -5.955996e-05  0.000753 -0.675992  0.704543  0.187277  0.107614  0.666667  0.115385     1.08  0.542016  0.149360  0.096692\n23014     B2      1           L   683.40800 -0.248256  0.269541 -0.284728 -0.294432 -0.006686  0.179921 -0.000573 -8.802837e-05  0.000918 -0.680782  0.702092  0.182901  0.100743  0.666667  0.192308     1.08  0.568125  0.150806  0.026587\n23015     B2      1           L   700.07000 -0.252823  0.269787 -0.269877 -0.298999 -0.006439  0.194773 -0.000274  1.480101e-05  0.000891 -0.686201  0.700481  0.174738  0.089001  0.750000  0.230769     1.12  0.648058  0.204180  0.011200\n23016     B2      1           L   716.74510 -0.258521  0.270667 -0.250517 -0.304697 -0.005559  0.214133 -0.000342  5.277542e-05  0.001161 -0.687601  0.700228  0.172051  0.085344  0.708333  0.153846     1.08  0.584754  0.159985  0.065597\n23017     B2      1           L   733.41800 -0.260742  0.270934 -0.231301 -0.306918 -0.005292  0.233349 -0.000133  1.603175e-05  0.001153 -0.692891  0.698661  0.162864  0.072457  0.666667  0.115385     1.00  0.537696  0.078098  0.079664\n23018     B2      1           L   750.08200 -0.262827  0.270249 -0.216254 -0.309003 -0.005977  0.248396 -0.000125 -4.111053e-05  0.000903 -0.699283  0.695606  0.153611  0.059489  0.708333  0.192308     1.00  0.594915  0.088413  0.012296\n23019     B2      1           L   766.76400 -0.262126  0.270943 -0.199324 -0.308301 -0.005284  0.265325  0.000042  4.155387e-05  0.001015 -0.706894  0.691561  0.141714  0.044285  0.708333  0.192308     1.00  0.587737  0.092371  0.003016\n23020     B2      1           L   783.42210 -0.263789  0.273021 -0.180260 -0.309964 -0.003205  0.284390 -0.000100  1.247910e-04  0.001144 -0.709423  0.690663  0.135439  0.036879  0.791667  0.269231     1.04  0.678051  0.147860 -0.059029\n23021     B2      1           L   800.08610 -0.260532  0.273995 -0.160662 -0.306707 -0.002231  0.303988  0.000195  5.842785e-05  0.001176 -0.713051  0.689807  0.123243  0.023162  0.791667  0.192308     0.96  0.667768  0.067410 -0.006406\n23022     B2      1           L   816.75600 -0.251356  0.273994 -0.140008 -0.297532 -0.002232  0.324642  0.000550 -3.039232e-08  0.001239 -0.716429  0.688231  0.113574  0.012956  0.833333  0.230769     0.96  0.712810  0.076401 -0.050615\n23023     B2      1           L   833.42800 -0.244854  0.275998 -0.120201 -0.291029 -0.000229  0.344448  0.000390  1.201549e-04  0.001188 -0.721090  0.685619  0.099775  0.000114  0.750000  0.307692     0.92  0.644976  0.030609 -0.159452\n23024     B2      1           L   850.09200 -0.240180  0.277547 -0.103671 -0.286355  0.001321  0.360978  0.000280  9.300168e-05  0.000992 -0.725020  0.682853  0.089233 -0.009752  0.708333  0.307692     0.88  0.604481 -0.013162 -0.177663\n23025     B2      1           L   866.76400 -0.227272  0.278597 -0.081270 -0.273448  0.002371  0.383380  0.000774  6.297779e-05  0.001344 -0.730442  0.678524  0.074098 -0.023865  0.750000  0.423077     0.84  0.650569 -0.035731 -0.306659\n23026     B2      1           L   883.44310 -0.216680  0.280669 -0.063762 -0.262856  0.004442  0.400887  0.000635  1.241944e-04  0.001050 -0.736276  0.673306  0.053268 -0.041450  0.791667  0.461539     0.88  0.671243  0.015208 -0.364610\n23027     B2      1           L   900.09700 -0.201147  0.281223 -0.042198 -0.247323  0.004997  0.422451  0.000933  3.329186e-05  0.001295 -0.738236  0.671340  0.046162 -0.046678  0.750000  0.538462     0.88  0.624669  0.017400 -0.448917\n23028     B2      1           L   916.76900 -0.176389  0.281599 -0.019837 -0.222565  0.005373  0.444812  0.001485  2.254659e-05  0.001341 -0.745361  0.663363  0.018178 -0.063693  0.666667  0.653846     0.88  0.516294  0.020653 -0.581436\n23029     B2      1           L   933.44010 -0.164708  0.281935 -0.007719 -0.210884  0.005708  0.456931  0.000701  2.012204e-05  0.000727 -0.749245  0.658108 -0.002969 -0.074284  0.500000  0.730769     0.84  0.331880 -0.027842 -0.659082\n23030     B2      1           L   950.10410 -0.151946  0.283721  0.004287 -0.198122  0.007494  0.468936  0.000766  1.071803e-04  0.000720 -0.750085  0.656702 -0.009305 -0.077637  0.416667  0.769231     0.80  0.242171 -0.070791 -0.695162\n23031     B2      1           L   966.77700 -0.120253  0.281845  0.031154 -0.166429  0.005618  0.495804  0.001901 -1.125118e-04  0.001611 -0.751375  0.653115 -0.029362 -0.089515  0.375000  0.769231     0.76  0.180033 -0.113369 -0.701009\n23032     B2      1           L   983.44700 -0.099263  0.283890  0.040987 -0.145439  0.007663  0.505637  0.001259  1.226562e-04  0.000590 -0.751106  0.650486 -0.048373 -0.101823  0.291667  0.730769     0.76  0.081037 -0.126415 -0.653433\n23033     B2      1           L  1000.11100 -0.080633  0.283744  0.049306 -0.126809  0.007518  0.513956  0.001118 -8.734668e-06  0.000499 -0.749881  0.648256 -0.065003 -0.114964  0.291667  0.807692     0.76  0.034972 -0.116538 -0.730279\n23034     B2      1           L  1016.78200 -0.060791  0.283845  0.055696 -0.106967  0.007619  0.520345  0.001190  6.076298e-06  0.000383 -0.747991  0.647432 -0.075939 -0.124797  0.250000  0.769231     0.80 -0.018315 -0.087512 -0.679152\n23035     B2      1           L  1033.45000 -0.033489  0.283755  0.067249 -0.079665  0.007529  0.531899  0.001638 -5.414042e-06  0.000693 -0.744638  0.646716 -0.089865 -0.138552  0.250000  0.730769     0.84 -0.037479 -0.056083 -0.640108\n23036     B2      1           L  1050.11600 -0.007844  0.283641  0.072779 -0.054020  0.007415  0.537428  0.001539 -6.818441e-06  0.000332 -0.743525  0.646567 -0.093735 -0.142601  0.291667  0.730769     0.88 -0.008473 -0.013824 -0.648751\n23037     B2      1           L  1066.78900  0.014907  0.281962  0.076757 -0.031269  0.005736  0.541407  0.001365 -1.007200e-04  0.000239 -0.739362  0.645910 -0.107453 -0.156839  0.333333  0.692308     0.92  0.012360  0.021346 -0.627297\n23038     B2      1           L  1083.47300  0.037915  0.282031  0.079259 -0.008260  0.005805  0.543909  0.001379  4.145969e-06  0.000150 -0.735627  0.644910 -0.121726 -0.167707  0.375000  0.692308     0.92  0.029032  0.021624 -0.649427\n23039     B2      1           L  1100.12200  0.061196  0.280756  0.081691  0.015020  0.004529  0.546341  0.001398 -7.660798e-05  0.000146 -0.733883  0.643397 -0.132683 -0.172773  0.208333  0.576923     0.84 -0.079407 -0.086132 -0.490289\n23040     B2      1           L  1116.79400  0.088260  0.280200  0.079902  0.042084  0.003974  0.544552  0.001623 -3.331489e-05 -0.000107 -0.733213  0.641100 -0.143304 -0.175650  0.166667  0.653846     0.84 -0.151681 -0.079674 -0.539339\n23041     B2      1           L  1133.49000  0.109642  0.279459  0.078112  0.063466  0.003232  0.542762  0.001281 -4.441241e-05 -0.000107 -0.732269  0.637575 -0.158459 -0.179360  0.125000  0.730769     0.80 -0.226250 -0.110313 -0.588996\n23042     B2      1           L  1150.13100  0.137403  0.279318  0.070889  0.091227  0.003092  0.535539  0.001668 -8.429757e-06 -0.000434 -0.730940  0.635211 -0.170024 -0.182554 -0.125000  0.807692     0.76 -0.486813 -0.151382 -0.537076\n23043     B2      1           L  1166.80200  0.159276  0.278893  0.066603  0.113100  0.002667  0.531253  0.001312 -2.550312e-05 -0.000257 -0.728513  0.634202 -0.178843 -0.187273 -0.166667  0.807692     0.80 -0.529492 -0.113532 -0.503941\n23044     B2      1           L  1183.49100  0.186099  0.277714  0.058907  0.139923  0.001488  0.523556  0.001607 -7.064376e-05 -0.000461 -0.724111  0.633689 -0.188647 -0.196249 -0.208333  0.769231     0.80 -0.560411 -0.123797 -0.439689\n23045     B2      1           L  1200.13500  0.209720  0.275478  0.050442  0.163544 -0.000749  0.515092  0.001419 -1.343868e-04 -0.000509 -0.722868  0.633489 -0.191050 -0.199133 -0.083333  0.730769     0.92 -0.435915 -0.004943 -0.455201\n23046     B2      1           L  1216.80900  0.228177  0.273738  0.042620  0.182001 -0.002488  0.507270  0.001107 -1.043237e-04 -0.000469 -0.718538  0.632339 -0.199657 -0.209732  0.083333  0.807692     1.04 -0.355479  0.126962 -0.586943\n23047     B2      1           L  1233.47700  0.246259  0.272131  0.033639  0.200083 -0.004096  0.498288  0.001085 -9.643575e-05 -0.000539 -0.715415  0.630247 -0.209776 -0.216711  0.041667  0.807692     1.00 -0.402940  0.084779 -0.561245\n23048     B2      1           L  1250.16600  0.267188  0.271084  0.021902  0.221012 -0.005142  0.486552  0.001254 -6.270483e-05 -0.000703 -0.712991  0.628994 -0.220375 -0.217819 -0.125000  0.769231     0.92 -0.516159 -0.003097 -0.439893\n23049     B2      1           L  1266.81300  0.282625  0.270542  0.010285  0.236449 -0.005684  0.474935  0.000927 -3.258418e-05 -0.000698 -0.712455  0.627472 -0.227869 -0.216247 -0.416667  0.884615     0.84 -0.815188 -0.070119 -0.364069\n23050     B2      1           L  1283.48200  0.299703  0.270001 -0.002915  0.253527 -0.006226  0.461734  0.001025 -3.245744e-05 -0.000792 -0.712275  0.626998 -0.230438 -0.215491 -0.625000  1.000000     0.84 -1.047766 -0.056678 -0.329478\n23051     B2      1           L  1300.14700  0.317341  0.268058 -0.019153  0.271165 -0.008168  0.445497  0.001058 -1.165623e-04 -0.000974 -0.709937  0.627314 -0.235277 -0.217052 -0.541667  1.038462     0.92 -1.000435  0.029669 -0.396379\n23052     B2      1           L  1316.82000  0.332036  0.267420 -0.036669  0.285860 -0.008807  0.427981  0.000881 -3.830354e-05 -0.001051 -0.706107  0.629517 -0.235108 -0.223262 -0.333333  0.961538     1.00 -0.800114  0.091148 -0.452637\n23053     B2      1           L  1333.48900  0.344784  0.265995 -0.051187  0.298608 -0.010231  0.413463  0.000765 -8.547746e-05 -0.000871 -0.699364  0.633753 -0.234603 -0.232827 -0.166667  0.538462     1.00 -0.432689  0.038520 -0.227982\n23054     B2      1           L  1350.15300  0.355426  0.265479 -0.073919  0.309251 -0.010747  0.390730  0.000639 -3.096468e-05 -0.001364 -0.693339  0.637806 -0.237843 -0.236464 -0.333333  0.461539     0.92 -0.523788 -0.056586 -0.078394\n23055     B2      1           L  1366.82400  0.358737  0.265263 -0.093620  0.312561 -0.010963  0.371029  0.000199 -1.293738e-05 -0.001182 -0.691066  0.640005 -0.240222 -0.234766 -0.583333  0.500000     0.92 -0.738695 -0.057058  0.043226\n23056     B2      1           L  1383.49900  0.362587  0.266039 -0.111121  0.316411 -0.010188  0.353528  0.000231  4.651327e-05 -0.001050 -0.690284  0.640777 -0.240777 -0.234394 -0.625000  0.538462     0.96 -0.793514 -0.014668  0.040283\n23057     B2      1           L  1400.15900  0.366761  0.266047 -0.131404  0.320586 -0.010180  0.333246  0.000251  4.668901e-07 -0.001217 -0.687734  0.643374 -0.240371 -0.235187 -0.625000  0.615385     0.96 -0.846169 -0.012933 -0.024901\n23058     B2      1           L  1416.83300  0.368751  0.265928 -0.154450  0.322575 -0.010298  0.310200  0.000119 -7.117260e-06 -0.001382 -0.682392  0.647956 -0.237562 -0.240952 -0.416667  0.461539     1.00 -0.603152  0.010453 -0.042679\n23059     B2      1           L  1433.50200  0.367786  0.266618 -0.171657  0.321610 -0.009609  0.292993 -0.000058  4.138946e-05 -0.001032 -0.677830  0.651708 -0.235767 -0.245433 -0.291667  0.269231     1.04 -0.396711  0.039877  0.020778\n23060     B2      1           L  1450.16500  0.365826  0.266923 -0.194083  0.319650 -0.009304  0.270567 -0.000118  1.828242e-05 -0.001346 -0.672960  0.657183 -0.233468 -0.246432 -0.375000  0.076923     1.08 -0.348137  0.071380  0.209495\n23061     B2      1           L  1466.83900  0.369041  0.264670 -0.206930  0.322865 -0.011556  0.257720  0.000193 -1.350840e-04 -0.000770 -0.673944  0.660053 -0.231814 -0.237471 -0.541667  0.153846     1.00 -0.519711 -0.005401  0.240304\n23062     B2      1           L  1483.50900  0.354109  0.266329 -0.234304  0.307933 -0.009897  0.230346 -0.000896  9.953342e-05 -0.001642 -0.676486  0.663319 -0.228127 -0.224348 -0.750000  0.269231     0.92 -0.749502 -0.075634  0.255303\n23063     B2      1           L  1500.17400  0.347952  0.267836 -0.250284  0.301777 -0.008390  0.214365 -0.000369  9.044039e-05 -0.000959 -0.675444  0.668900 -0.220525 -0.218441 -0.583333  0.192308     0.96 -0.578963 -0.038219  0.196569\n23064     B2      1           L  1516.85700  0.343112  0.267523 -0.269539  0.296936 -0.008704  0.195110 -0.000290 -1.880176e-05 -0.001154 -0.670791  0.677326 -0.211115 -0.216100 -0.500000  0.115385     1.00 -0.484693 -0.003294  0.186983\n23065     B2      1           L  1533.51500  0.334145  0.268016 -0.285450  0.287969 -0.008210  0.179200 -0.000538  2.961633e-05 -0.000955 -0.668332  0.681534 -0.206787 -0.214670 -0.166667 -0.115385     1.12 -0.089571  0.121329  0.173466\n23066     B2      1           L  1550.17900  0.321787  0.268350 -0.303581  0.275611 -0.007876  0.161069 -0.000742  2.006427e-05 -0.001088 -0.665302  0.692088 -0.194130 -0.201744 -0.125000 -0.346154     1.12  0.057083  0.132795  0.321505\n23067     B2      1           L  1566.85100  0.304557  0.267992 -0.320148  0.258382 -0.008234  0.144501 -0.001033 -2.149729e-05 -0.000994 -0.666019  0.693953 -0.191148 -0.195730 -0.208333 -0.307692     1.08 -0.033697  0.092322  0.331925\n23068     B2      1           L  1583.51800  0.294115  0.268978 -0.334681  0.247940 -0.007249  0.129969 -0.000627  5.912188e-05 -0.000872 -0.671610  0.697977 -0.181560 -0.169716 -0.458333 -0.076923     1.00 -0.357722  0.013302  0.247469\n23069     B2      1           L  1600.18300  0.287430  0.269708 -0.342520  0.241255 -0.006518  0.122130 -0.000401  4.384588e-05 -0.000470 -0.676869  0.701177 -0.170384 -0.145495 -0.500000  0.038462     1.00 -0.439948  0.018791  0.141384\n23070     B2      1           L  1616.85500  0.268007  0.270228 -0.362152  0.221831 -0.005998  0.102498 -0.001165  3.120556e-05 -0.001178 -0.678410  0.704244 -0.161806 -0.132736 -0.416667  0.076923     0.96 -0.380270 -0.023623  0.056667\n23071     B2      1           L  1633.52700  0.259291  0.272046 -0.368608  0.213116 -0.004181  0.096042 -0.000523  1.090094e-04 -0.000387 -0.675624  0.713183 -0.144504 -0.118407 -0.041667 -0.076923     1.08  0.017883  0.083147  0.022925\n23072     B2      1           L  1650.19100  0.239615  0.271615 -0.386312  0.193439 -0.004611  0.078338 -0.001181 -2.583211e-05 -0.001062 -0.672815  0.722363 -0.123409 -0.101403  0.125000 -0.346154     1.12  0.249482  0.133694  0.205774\n23073     B2      1           L  1666.86200  0.223113  0.273575 -0.396251  0.176937 -0.002651  0.068399 -0.000990  1.175520e-04 -0.000596 -0.676442  0.725765 -0.101868 -0.072908 -0.041667 -0.192308     1.04  0.040313  0.050976  0.118926\n23074     B2      1           L  1683.53300  0.203542  0.272858 -0.410156  0.157366 -0.003368  0.054493 -0.001174 -4.299888e-05 -0.000834 -0.681805  0.724573 -0.088157 -0.048622 -0.125000 -0.038462     0.96 -0.067241 -0.033470 -0.001429\n23075     B2      1           L  1700.19500  0.189037  0.273912 -0.418042  0.142861 -0.002315  0.046608 -0.000871  6.323204e-05 -0.000473 -0.686917  0.723464 -0.065812 -0.020336 -0.083333  0.153846     0.96 -0.042940 -0.044987 -0.195756\n23076     B2      1           L  1716.86400  0.170708  0.275335 -0.429827  0.124533 -0.000892  0.034823 -0.001100  8.536420e-05 -0.000707 -0.687422  0.724372 -0.051794 -0.007331  0.041667  0.115385     1.00  0.092206 -0.011765 -0.173028\n23077     B2      1           L  1733.53800  0.155890  0.277158 -0.437038  0.109715  0.000932  0.027611 -0.000889  1.093649e-04 -0.000432 -0.684852  0.727940 -0.031998  0.007577  0.291667 -0.230769     1.04  0.356445  0.033651  0.156323\n23078     B2      1           L  1750.20000  0.139727  0.277694 -0.447256  0.093551  0.001467  0.017394 -0.000970  3.213831e-05 -0.000613 -0.681714  0.731013 -0.008207  0.028616  0.333333 -0.384615     1.00  0.375378  0.006285  0.324842\n23079     B2      1           L  1766.89800  0.122326  0.280266 -0.456208  0.076150  0.004040  0.008441 -0.001042  1.540715e-04 -0.000536 -0.680415  0.730912  0.014951  0.050792  0.375000 -0.384615     0.96  0.389654 -0.033088  0.351291\n23080     B2      1           L  1783.54200  0.109845  0.280601 -0.462796  0.063670  0.004375  0.001854 -0.000750  2.009019e-05 -0.000396 -0.679298  0.730210  0.031150  0.066165  0.375000 -0.423077     0.92  0.363675 -0.068360  0.407194\n23081     B2      1           L  1800.20600  0.093857  0.282172 -0.472300  0.047681  0.005945 -0.007650 -0.000959  9.425929e-05 -0.000570 -0.678641  0.729879  0.038300  0.072493  0.416667 -0.461539     0.96  0.391533 -0.026287  0.454767\n23082     B2      1           L  1816.87800  0.077229  0.283390 -0.480999  0.031053  0.007164 -0.016349 -0.000997  7.310435e-05 -0.000522 -0.675073  0.729482  0.062940  0.090388  0.500000 -0.423077     1.00  0.444282  0.015294  0.448092\n23083     B2      1           L  1833.54700  0.063921  0.283913 -0.486775  0.017746  0.007687 -0.022125 -0.000798  3.134871e-05 -0.000347 -0.672427  0.730339  0.073020  0.095476  0.666667 -0.423077     1.08  0.592515  0.097308  0.484438\n23084     B2      1           L  1850.21100  0.051641  0.284432 -0.492428  0.005465  0.008206 -0.027779 -0.000737  3.114196e-05 -0.000339 -0.668117  0.732585  0.084283  0.099175  0.791667 -0.423077     1.16  0.694450  0.187132  0.509695\n23085     B2      1           L  1866.88300  0.040971  0.284699 -0.495705 -0.005205  0.008472 -0.031055 -0.000640  1.599694e-05 -0.000197 -0.667312  0.732845  0.087042  0.100286  0.750000 -0.384615     1.12  0.657521  0.146538  0.466846\n23086     B2      1           L  1883.55200  0.029840  0.285829 -0.498527 -0.016336  0.009603 -0.033878 -0.000668  6.782150e-05 -0.000169 -0.668266  0.731234  0.090907  0.102244  0.500000 -0.192308     1.08  0.459706  0.091095  0.227076\n23087     B2      1           L  1900.21600  0.021282  0.286547 -0.498999 -0.024894  0.010321 -0.034350 -0.000514  4.309047e-05 -0.000028 -0.673125  0.726405  0.093878  0.102106  0.291667  0.000000     0.96  0.301523 -0.043103  0.010092\n"
     ]
    }
   ],
   "source": [
    "k = ['tester', 'timestamp', 'trial', 'posX', 'posY', 'posZ']\n",
    "#dataframe = dataframe[k]\n",
    "df_array = dataframe.values\n",
    "#df_array\n",
    "\n",
    "\n",
    "grouped_df = dataframe.groupby(['tester'])\n",
    "gb = grouped_df.groups\n",
    "\n",
    "for key, val in gb.items():\n",
    "    print(df.ix[val], '\\n\\n')\n",
    "    \n",
    "    if key == 'B2': break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([(1, 'B1'), (2, 'B1'), (3, 'B1'), (4, 'B1'), (5, 'B1'), (6, 'B1'), (7, 'B1'), (8, 'B1'), (9, 'B1'), (10, 'B1'), (1, 'B2'), (2, 'B2'), (3, 'B2'), (4, 'B2'), (5, 'B2'), (6, 'B2'), (7, 'B2'), (8, 'B2'), (9, 'B2'), (10, 'B2'), (1, 'C1'), (2, 'C1'), (3, 'C1'), (4, 'C1'), (5, 'C1'), (6, 'C1'), (7, 'C1'), (8, 'C1'), (9, 'C1'), (10, 'C1'), (1, 'C2'), (2, 'C2'), (3, 'C2'), (4, 'C2'), (5, 'C2'), (6, 'C2'), (7, 'C2'), (8, 'C2'), (9, 'C2'), (10, 'C2'), (1, 'D1'), (2, 'D1'), (3, 'D1'), (4, 'D1'), (5, 'D1'), (6, 'D1'), (7, 'D1'), (8, 'D1'), (9, 'D1'), (10, 'D1'), (1, 'D2'), (2, 'D2'), (3, 'D2'), (4, 'D2'), (5, 'D2'), (6, 'D2'), (7, 'D2'), (8, 'D2'), (9, 'D2'), (10, 'D2'), (1, 'F1'), (2, 'F1'), (3, 'F1'), (4, 'F1'), (5, 'F1'), (6, 'F1'), (7, 'F1'), (8, 'F1'), (9, 'F1'), (10, 'F1'), (1, 'J1'), (2, 'J1'), (3, 'J1'), (4, 'J1'), (5, 'J1'), (6, 'J1'), (7, 'J1'), (8, 'J1'), (9, 'J1'), (10, 'J1'), (1, 'J2'), (2, 'J2'), (3, 'J2'), (4, 'J2'), (5, 'J2'), (6, 'J2'), (7, 'J2'), (8, 'J2'), (9, 'J2'), (10, 'J2'), (1, 'J3'), (2, 'J3'), (3, 'J3'), (4, 'J3'), (5, 'J3'), (6, 'J3'), (7, 'J3'), (8, 'J3'), (9, 'J3'), (10, 'J3'), (1, 'J4'), (2, 'J4'), (3, 'J4'), (4, 'J4'), (5, 'J4'), (6, 'J4'), (7, 'J4'), (8, 'J4'), (9, 'J4'), (10, 'J4'), (1, 'J5'), (2, 'J5'), (3, 'J5'), (4, 'J5'), (5, 'J5'), (6, 'J5'), (7, 'J5'), (8, 'J5'), (9, 'J5'), (10, 'J5'), (1, 'M1'), (2, 'M1'), (3, 'M1'), (4, 'M1'), (5, 'M1'), (6, 'M1'), (7, 'M1'), (8, 'M1'), (9, 'M1'), (10, 'M1'), (1, 'M2'), (2, 'M2'), (3, 'M2'), (4, 'M2'), (5, 'M2'), (6, 'M2'), (7, 'M2'), (8, 'M2'), (9, 'M2'), (10, 'M2'), (1, 'M3'), (2, 'M3'), (3, 'M3'), (4, 'M3'), (5, 'M3'), (6, 'M3'), (7, 'M3'), (8, 'M3'), (9, 'M3'), (10, 'M3'), (1, 'R1'), (2, 'R1'), (3, 'R1'), (4, 'R1'), (5, 'R1'), (6, 'R1'), (7, 'R1'), (8, 'R1'), (9, 'R1'), (10, 'R1'), (1, 'R2'), (2, 'R2'), (3, 'R2'), (4, 'R2'), (5, 'R2'), (6, 'R2'), (7, 'R2'), (8, 'R2'), (9, 'R2'), (10, 'R2'), (1, 'S1'), (2, 'S1'), (3, 'S1'), (4, 'S1'), (5, 'S1'), (6, 'S1'), (7, 'S1'), (8, 'S1'), (9, 'S1'), (10, 'S1'), (1, 'S2'), (2, 'S2'), (3, 'S2'), (4, 'S2'), (5, 'S2'), (6, 'S2'), (7, 'S2'), (8, 'S2'), (9, 'S2'), (10, 'S2'), (1, 'S3'), (2, 'S3'), (3, 'S3'), (4, 'S3'), (5, 'S3'), (6, 'S3'), (7, 'S3'), (8, 'S3'), (9, 'S3'), (10, 'S3'), (1, 'T1'), (2, 'T1'), (3, 'T1'), (4, 'T1'), (5, 'T1'), (6, 'T1'), (7, 'T1'), (8, 'T1'), (9, 'T1'), (10, 'T1'), (1, 'T2'), (2, 'T2'), (3, 'T2'), (4, 'T2'), (5, 'T2'), (6, 'T2'), (7, 'T2'), (8, 'T2'), (9, 'T2'), (10, 'T2'), (1, 'U1'), (2, 'U1'), (3, 'U1'), (4, 'U1'), (5, 'U1'), (6, 'U1'), (7, 'U1'), (8, 'U1'), (9, 'U1'), (10, 'U1'), (1, 'W1'), (2, 'W1'), (3, 'W1'), (4, 'W1'), (5, 'W1'), (6, 'W1'), (7, 'W1'), (8, 'W1'), (9, 'W1'), (10, 'W1'), (1, 'W2'), (2, 'W2'), (3, 'W2'), (4, 'W2'), (5, 'W2'), (6, 'W2'), (7, 'W2'), (8, 'W2'), (9, 'W2'), (10, 'W2'), (1, 'Y1'), (2, 'Y1'), (3, 'Y1'), (4, 'Y1'), (5, 'Y1'), (6, 'Y1'), (7, 'Y1'), (8, 'Y1'), (9, 'Y1'), (10, 'Y1'), (1, 'Y2'), (2, 'Y2'), (3, 'Y2'), (4, 'Y2'), (5, 'Y2'), (6, 'Y2'), (7, 'Y2'), (8, 'Y2'), (9, 'Y2'), (10, 'Y2'), (1, 'Y3'), (2, 'Y3'), (3, 'Y3'), (4, 'Y3'), (5, 'Y3'), (6, 'Y3'), (7, 'Y3'), (8, 'Y3'), (9, 'Y3'), (10, 'Y3')]) \n\n280 \n\n      tester  trial rightHanded   timestamp      posX      posY      posZ   posRelX   posRelY   posRelZ      velX          velY      velZ     quatW     quatX     quatY     quatZ   accRelX   accRelY  accRelZ   accAbsX   accAbsY   accAbsZ\n22974     B2      1           L    16.66000  0.046176  0.276226 -0.464650  0.000000  0.000000  0.000000  0.000000  0.000000e+00  0.000000 -0.702897  0.708961  0.028066  0.050223 -0.041667  0.038462     0.96 -0.006658 -0.039619 -0.049389\n22975     B2      1           L    33.32500  0.046074  0.276587 -0.465288 -0.000102  0.000360 -0.000638 -0.000006  2.161540e-05 -0.000038 -0.703015  0.708776  0.026372  0.052079 -0.083333  0.000000     1.00 -0.046020  0.002293 -0.015358\n22976     B2      1           L    49.99500  0.045457  0.276681 -0.465823 -0.000719  0.000454 -0.001173 -0.000037  5.654752e-06 -0.000032 -0.703015  0.708776  0.026372  0.052079 -0.083333  0.000000     1.00 -0.046020  0.002293 -0.015358\n22977     B2      1           L    66.66600  0.045431  0.276679 -0.465889 -0.000745  0.000453 -0.001239 -0.000002 -1.144112e-07 -0.000004 -0.705571  0.706068  0.028408  0.053191 -0.083333  0.076923     1.00 -0.038842  0.002088 -0.084691\n22978     B2      1           L    83.33401  0.045204  0.276640 -0.466186 -0.000971  0.000414 -0.001536 -0.000014 -2.319030e-06 -0.000018 -0.705773  0.705807  0.028492  0.053943 -0.166667  0.115385     1.00 -0.116072  0.005092 -0.131945\n22979     B2      1           L   100.00300  0.044031  0.276621 -0.467819 -0.002144  0.000395 -0.003170 -0.000070 -1.147825e-06 -0.000098 -0.705881  0.705271  0.030153  0.058443 -0.166667  0.038462     1.00 -0.120548  0.005798 -0.055628\n22980     B2      1           L   116.67100  0.043771  0.276433 -0.467986 -0.002405  0.000206 -0.003336 -0.000016 -1.130908e-05 -0.000010 -0.705881  0.705271  0.030153  0.058443 -0.166667  0.038462     1.00 -0.120548  0.005798 -0.055628\n22981     B2      1           L   133.33800  0.042781  0.276837 -0.469208 -0.003395  0.000610 -0.004558 -0.000059  2.424131e-05 -0.000073 -0.701492  0.709037  0.032668  0.064099 -0.208333 -0.115385     1.00 -0.176835  0.009618  0.078212\n22982     B2      1           L   150.00800  0.042138  0.276817 -0.470323 -0.004037  0.000591 -0.005673 -0.000039 -1.158483e-06 -0.000067 -0.699122  0.710853  0.035607  0.068185 -0.250000 -0.192308     0.96 -0.229845 -0.026141  0.140895\n22983     B2      1           L   166.67900  0.039595  0.276719 -0.473156 -0.006581  0.000492 -0.008506 -0.000153 -5.918993e-06 -0.000170 -0.697881  0.711441  0.039428  0.072515 -0.250000 -0.192308     0.96 -0.230624 -0.025562  0.135519\n22984     B2      1           L   183.35900  0.036453  0.276665 -0.474754 -0.009723  0.000439 -0.010105 -0.000188 -3.226796e-06 -0.000096 -0.696812  0.711478  0.045775  0.078462 -0.250000 -0.192308     0.92 -0.235402 -0.065375  0.130173\n22985     B2      1           L   200.01300  0.033984  0.276621 -0.476795 -0.012191  0.000395 -0.012145 -0.000148 -2.639510e-06 -0.000123 -0.696234  0.711514  0.049063  0.081233 -0.291667 -0.269231     0.92 -0.292167 -0.061619  0.195022\n22986     B2      1           L   216.68400  0.031747  0.276729 -0.477728 -0.014429  0.000502 -0.013078 -0.000134  6.460659e-06 -0.000056 -0.694752  0.711566  0.057938  0.087389 -0.250000 -0.230769     0.96 -0.249446 -0.024916  0.156022\n22987     B2      1           L   233.35000  0.026647  0.276650 -0.477661 -0.019529  0.000423 -0.013012 -0.000306 -4.733393e-06  0.000004 -0.694113  0.711678  0.061012  0.089438 -0.208333 -0.230769     1.00 -0.209539  0.013343  0.160891\n22988     B2      1           L   250.02100  0.022670  0.276057 -0.477260 -0.023506 -0.000169 -0.012610 -0.000239 -3.554611e-05  0.000024 -0.692165  0.711904  0.070123  0.095829 -0.166667 -0.230769     1.00 -0.176252  0.011799  0.161957\n22989     B2      1           L   266.68900  0.015826  0.276280 -0.476019 -0.030350  0.000054 -0.011369 -0.000411  1.338493e-05  0.000074 -0.690886  0.711006  0.079976  0.103684 -0.125000 -0.230769     1.00 -0.143089  0.010240  0.166796\n22990     B2      1           L   283.36000  0.009658  0.275564 -0.475491 -0.036518 -0.000662 -0.010841 -0.000370 -4.295248e-05  0.000032 -0.690748  0.708305  0.090666  0.113804 -0.166667 -0.153846     1.00 -0.167595  0.008460  0.079789\n22991     B2      1           L   300.02600  0.001912  0.274828 -0.473538 -0.044264 -0.001398 -0.008888 -0.000465 -4.414560e-05  0.000117 -0.690148  0.706998  0.097531  0.119734 -0.166667 -0.153846     1.00 -0.170678  0.008147  0.077168\n22992     B2      1           L   316.69600 -0.006702  0.274787 -0.471547 -0.052878 -0.001440 -0.006897 -0.000517 -2.510043e-06  0.000119 -0.687361  0.707140  0.106830  0.126786 -0.125000 -0.192308     1.04 -0.146954  0.048281  0.117129\n22993     B2      1           L   333.36300 -0.015558  0.274564 -0.470000 -0.061734 -0.001663 -0.005350 -0.000531 -1.337502e-05  0.000093 -0.686123  0.707465  0.110059  0.128900 -0.083333 -0.192308     1.04 -0.109898  0.047505  0.127206\n22994     B2      1           L   350.02800 -0.024582  0.273761 -0.467359 -0.070758 -0.002466 -0.002709 -0.000542 -4.818441e-05  0.000158 -0.682816  0.707880  0.120113  0.135059  0.000000 -0.269231     1.04 -0.067172  0.049526  0.219247\n22995     B2      1           L   366.70300 -0.034642  0.273023 -0.463970 -0.080818 -0.003203  0.000679 -0.000603 -4.424151e-05  0.000203 -0.680824  0.706134  0.131306  0.143568  0.000000 -0.269231     1.00 -0.078594  0.009567  0.216983\n22996     B2      1           L   383.37100 -0.043691  0.272807 -0.460077 -0.089867 -0.003420  0.004573 -0.000543 -1.297010e-05  0.000234 -0.680025  0.704449  0.137806  0.149423 -0.083333 -0.230769     1.00 -0.145050  0.008598  0.147952\n22997     B2      1           L   400.03700 -0.055371  0.273220 -0.455605 -0.101546 -0.003006  0.009045 -0.000701  2.479535e-05  0.000268 -0.678387  0.703453  0.145257  0.154420  0.000000 -0.192308     1.00 -0.059417  0.006477  0.143025\n22998     B2      1           L   416.70700 -0.066380  0.273998 -0.449916 -0.112556 -0.002229  0.014734 -0.000660  4.665928e-05  0.000341 -0.675100  0.703970  0.153923  0.158029  0.041667 -0.230769     1.04 -0.046384  0.048738  0.185977\n22999     B2      1           L   433.39300 -0.077091  0.273701 -0.444537 -0.123267 -0.002525  0.020112 -0.000642 -1.777676e-05  0.000322 -0.670882  0.705939  0.161313  0.159829  0.083333 -0.192308     1.04 -0.000716  0.049018  0.158387\n23000     B2      1           L   450.04400 -0.089340  0.273588 -0.438633 -0.135516 -0.002639  0.026016 -0.000736 -6.819220e-06  0.000355 -0.668747  0.707136  0.164312  0.160426  0.125000 -0.269231     1.00 -0.001397  0.014618  0.242193\n23001     B2      1           L   466.71400 -0.101809  0.272931 -0.432776 -0.147985 -0.003295  0.031874 -0.000748 -3.939731e-05  0.000351 -0.664090  0.710080  0.170509  0.160306  0.208333 -0.346154     1.00  0.029184  0.024579  0.335575\n23002     B2      1           L   483.39700 -0.114633  0.272429 -0.425850 -0.160808 -0.003798  0.038800 -0.000769 -3.009526e-05  0.000415 -0.661953  0.710371  0.177803  0.159931  0.333333 -0.307692     1.04  0.143830  0.069443  0.350700\n23003     B2      1           L   500.04900 -0.127303  0.272556 -0.418219 -0.173479 -0.003671  0.046431 -0.000761  7.604505e-06  0.000458 -0.661915  0.709357  0.181691  0.160217  0.333333 -0.192308     1.00  0.190628  0.023610  0.252939\n23004     B2      1           L   516.71700 -0.139577  0.272501 -0.410628 -0.185753 -0.003725  0.054022 -0.000736 -3.264875e-06  0.000455 -0.661789  0.708725  0.185103  0.159627  0.208333 -0.153846     0.96  0.092585 -0.023548  0.163220\n23005     B2      1           L   533.38900 -0.151437  0.272624 -0.400840 -0.197613 -0.003602  0.063809 -0.000711  7.377291e-06  0.000587 -0.661789  0.708725  0.185103  0.159627  0.208333 -0.153846     0.96  0.092585 -0.023548  0.163220\n23006     B2      1           L   550.05600 -0.164111  0.272932 -0.389769 -0.210286 -0.003295  0.074880 -0.000760  1.846218e-05  0.000664 -0.661686  0.708339  0.191080  0.154647  0.375000 -0.076923     1.00  0.259329  0.025210  0.168033\n23007     B2      1           L   566.72500 -0.178487  0.272788 -0.377576 -0.224663 -0.003438  0.087073 -0.000862 -8.601530e-06  0.000731 -0.663755  0.706448  0.193313  0.151626  0.333333  0.000000     0.96  0.252396 -0.019469  0.086989\n23008     B2      1           L   583.39800 -0.188321  0.272749 -0.366179 -0.234497 -0.003477  0.098471 -0.000590 -2.330851e-06  0.000684 -0.664629  0.705797  0.193965  0.149989  0.333333  0.038462     0.96  0.267191 -0.020263  0.053989\n23009     B2      1           L   600.06300 -0.198577  0.272840 -0.354137 -0.244753 -0.003386  0.110513 -0.000615  5.422167e-06  0.000723 -0.666115  0.705333  0.195340  0.143662  0.416667  0.038462     0.96  0.330354 -0.010365  0.090440\n23010     B2      1           L   616.73400 -0.211027  0.272010 -0.339649 -0.257202 -0.004216  0.125001 -0.000747 -4.974752e-05  0.000869 -0.666617  0.707283  0.194952  0.131781  0.583333  0.038462     1.00  0.462592  0.051379  0.149556\n23011     B2      1           L   633.40410 -0.221438  0.271820 -0.327228 -0.267614 -0.004406  0.137422 -0.000625 -1.142032e-05  0.000745 -0.666953  0.707862  0.194529  0.127533  0.666667 -0.038462     1.04  0.495302  0.105112  0.246832\n23012     B2      1           L   650.06900 -0.231581  0.272001 -0.312575 -0.277757 -0.004226  0.152075 -0.000609  1.082828e-05  0.000879 -0.670113  0.707253  0.192388  0.117168  0.750000  0.038462     1.08  0.590916  0.157655  0.202566\n23013     B2      1           L   666.74100 -0.238708  0.271008 -0.300022 -0.284884 -0.005219  0.164628 -0.000427 -5.955996e-05  0.000753 -0.675992  0.704543  0.187277  0.107614  0.666667  0.115385     1.08  0.542016  0.149360  0.096692\n23014     B2      1           L   683.40800 -0.248256  0.269541 -0.284728 -0.294432 -0.006686  0.179921 -0.000573 -8.802837e-05  0.000918 -0.680782  0.702092  0.182901  0.100743  0.666667  0.192308     1.08  0.568125  0.150806  0.026587\n23015     B2      1           L   700.07000 -0.252823  0.269787 -0.269877 -0.298999 -0.006439  0.194773 -0.000274  1.480101e-05  0.000891 -0.686201  0.700481  0.174738  0.089001  0.750000  0.230769     1.12  0.648058  0.204180  0.011200\n23016     B2      1           L   716.74510 -0.258521  0.270667 -0.250517 -0.304697 -0.005559  0.214133 -0.000342  5.277542e-05  0.001161 -0.687601  0.700228  0.172051  0.085344  0.708333  0.153846     1.08  0.584754  0.159985  0.065597\n23017     B2      1           L   733.41800 -0.260742  0.270934 -0.231301 -0.306918 -0.005292  0.233349 -0.000133  1.603175e-05  0.001153 -0.692891  0.698661  0.162864  0.072457  0.666667  0.115385     1.00  0.537696  0.078098  0.079664\n23018     B2      1           L   750.08200 -0.262827  0.270249 -0.216254 -0.309003 -0.005977  0.248396 -0.000125 -4.111053e-05  0.000903 -0.699283  0.695606  0.153611  0.059489  0.708333  0.192308     1.00  0.594915  0.088413  0.012296\n23019     B2      1           L   766.76400 -0.262126  0.270943 -0.199324 -0.308301 -0.005284  0.265325  0.000042  4.155387e-05  0.001015 -0.706894  0.691561  0.141714  0.044285  0.708333  0.192308     1.00  0.587737  0.092371  0.003016\n23020     B2      1           L   783.42210 -0.263789  0.273021 -0.180260 -0.309964 -0.003205  0.284390 -0.000100  1.247910e-04  0.001144 -0.709423  0.690663  0.135439  0.036879  0.791667  0.269231     1.04  0.678051  0.147860 -0.059029\n23021     B2      1           L   800.08610 -0.260532  0.273995 -0.160662 -0.306707 -0.002231  0.303988  0.000195  5.842785e-05  0.001176 -0.713051  0.689807  0.123243  0.023162  0.791667  0.192308     0.96  0.667768  0.067410 -0.006406\n23022     B2      1           L   816.75600 -0.251356  0.273994 -0.140008 -0.297532 -0.002232  0.324642  0.000550 -3.039232e-08  0.001239 -0.716429  0.688231  0.113574  0.012956  0.833333  0.230769     0.96  0.712810  0.076401 -0.050615\n23023     B2      1           L   833.42800 -0.244854  0.275998 -0.120201 -0.291029 -0.000229  0.344448  0.000390  1.201549e-04  0.001188 -0.721090  0.685619  0.099775  0.000114  0.750000  0.307692     0.92  0.644976  0.030609 -0.159452\n23024     B2      1           L   850.09200 -0.240180  0.277547 -0.103671 -0.286355  0.001321  0.360978  0.000280  9.300168e-05  0.000992 -0.725020  0.682853  0.089233 -0.009752  0.708333  0.307692     0.88  0.604481 -0.013162 -0.177663\n23025     B2      1           L   866.76400 -0.227272  0.278597 -0.081270 -0.273448  0.002371  0.383380  0.000774  6.297779e-05  0.001344 -0.730442  0.678524  0.074098 -0.023865  0.750000  0.423077     0.84  0.650569 -0.035731 -0.306659\n23026     B2      1           L   883.44310 -0.216680  0.280669 -0.063762 -0.262856  0.004442  0.400887  0.000635  1.241944e-04  0.001050 -0.736276  0.673306  0.053268 -0.041450  0.791667  0.461539     0.88  0.671243  0.015208 -0.364610\n23027     B2      1           L   900.09700 -0.201147  0.281223 -0.042198 -0.247323  0.004997  0.422451  0.000933  3.329186e-05  0.001295 -0.738236  0.671340  0.046162 -0.046678  0.750000  0.538462     0.88  0.624669  0.017400 -0.448917\n23028     B2      1           L   916.76900 -0.176389  0.281599 -0.019837 -0.222565  0.005373  0.444812  0.001485  2.254659e-05  0.001341 -0.745361  0.663363  0.018178 -0.063693  0.666667  0.653846     0.88  0.516294  0.020653 -0.581436\n23029     B2      1           L   933.44010 -0.164708  0.281935 -0.007719 -0.210884  0.005708  0.456931  0.000701  2.012204e-05  0.000727 -0.749245  0.658108 -0.002969 -0.074284  0.500000  0.730769     0.84  0.331880 -0.027842 -0.659082\n23030     B2      1           L   950.10410 -0.151946  0.283721  0.004287 -0.198122  0.007494  0.468936  0.000766  1.071803e-04  0.000720 -0.750085  0.656702 -0.009305 -0.077637  0.416667  0.769231     0.80  0.242171 -0.070791 -0.695162\n23031     B2      1           L   966.77700 -0.120253  0.281845  0.031154 -0.166429  0.005618  0.495804  0.001901 -1.125118e-04  0.001611 -0.751375  0.653115 -0.029362 -0.089515  0.375000  0.769231     0.76  0.180033 -0.113369 -0.701009\n23032     B2      1           L   983.44700 -0.099263  0.283890  0.040987 -0.145439  0.007663  0.505637  0.001259  1.226562e-04  0.000590 -0.751106  0.650486 -0.048373 -0.101823  0.291667  0.730769     0.76  0.081037 -0.126415 -0.653433\n23033     B2      1           L  1000.11100 -0.080633  0.283744  0.049306 -0.126809  0.007518  0.513956  0.001118 -8.734668e-06  0.000499 -0.749881  0.648256 -0.065003 -0.114964  0.291667  0.807692     0.76  0.034972 -0.116538 -0.730279\n23034     B2      1           L  1016.78200 -0.060791  0.283845  0.055696 -0.106967  0.007619  0.520345  0.001190  6.076298e-06  0.000383 -0.747991  0.647432 -0.075939 -0.124797  0.250000  0.769231     0.80 -0.018315 -0.087512 -0.679152\n23035     B2      1           L  1033.45000 -0.033489  0.283755  0.067249 -0.079665  0.007529  0.531899  0.001638 -5.414042e-06  0.000693 -0.744638  0.646716 -0.089865 -0.138552  0.250000  0.730769     0.84 -0.037479 -0.056083 -0.640108\n23036     B2      1           L  1050.11600 -0.007844  0.283641  0.072779 -0.054020  0.007415  0.537428  0.001539 -6.818441e-06  0.000332 -0.743525  0.646567 -0.093735 -0.142601  0.291667  0.730769     0.88 -0.008473 -0.013824 -0.648751\n23037     B2      1           L  1066.78900  0.014907  0.281962  0.076757 -0.031269  0.005736  0.541407  0.001365 -1.007200e-04  0.000239 -0.739362  0.645910 -0.107453 -0.156839  0.333333  0.692308     0.92  0.012360  0.021346 -0.627297\n23038     B2      1           L  1083.47300  0.037915  0.282031  0.079259 -0.008260  0.005805  0.543909  0.001379  4.145969e-06  0.000150 -0.735627  0.644910 -0.121726 -0.167707  0.375000  0.692308     0.92  0.029032  0.021624 -0.649427\n23039     B2      1           L  1100.12200  0.061196  0.280756  0.081691  0.015020  0.004529  0.546341  0.001398 -7.660798e-05  0.000146 -0.733883  0.643397 -0.132683 -0.172773  0.208333  0.576923     0.84 -0.079407 -0.086132 -0.490289\n23040     B2      1           L  1116.79400  0.088260  0.280200  0.079902  0.042084  0.003974  0.544552  0.001623 -3.331489e-05 -0.000107 -0.733213  0.641100 -0.143304 -0.175650  0.166667  0.653846     0.84 -0.151681 -0.079674 -0.539339\n23041     B2      1           L  1133.49000  0.109642  0.279459  0.078112  0.063466  0.003232  0.542762  0.001281 -4.441241e-05 -0.000107 -0.732269  0.637575 -0.158459 -0.179360  0.125000  0.730769     0.80 -0.226250 -0.110313 -0.588996\n23042     B2      1           L  1150.13100  0.137403  0.279318  0.070889  0.091227  0.003092  0.535539  0.001668 -8.429757e-06 -0.000434 -0.730940  0.635211 -0.170024 -0.182554 -0.125000  0.807692     0.76 -0.486813 -0.151382 -0.537076\n23043     B2      1           L  1166.80200  0.159276  0.278893  0.066603  0.113100  0.002667  0.531253  0.001312 -2.550312e-05 -0.000257 -0.728513  0.634202 -0.178843 -0.187273 -0.166667  0.807692     0.80 -0.529492 -0.113532 -0.503941\n23044     B2      1           L  1183.49100  0.186099  0.277714  0.058907  0.139923  0.001488  0.523556  0.001607 -7.064376e-05 -0.000461 -0.724111  0.633689 -0.188647 -0.196249 -0.208333  0.769231     0.80 -0.560411 -0.123797 -0.439689\n23045     B2      1           L  1200.13500  0.209720  0.275478  0.050442  0.163544 -0.000749  0.515092  0.001419 -1.343868e-04 -0.000509 -0.722868  0.633489 -0.191050 -0.199133 -0.083333  0.730769     0.92 -0.435915 -0.004943 -0.455201\n23046     B2      1           L  1216.80900  0.228177  0.273738  0.042620  0.182001 -0.002488  0.507270  0.001107 -1.043237e-04 -0.000469 -0.718538  0.632339 -0.199657 -0.209732  0.083333  0.807692     1.04 -0.355479  0.126962 -0.586943\n23047     B2      1           L  1233.47700  0.246259  0.272131  0.033639  0.200083 -0.004096  0.498288  0.001085 -9.643575e-05 -0.000539 -0.715415  0.630247 -0.209776 -0.216711  0.041667  0.807692     1.00 -0.402940  0.084779 -0.561245\n23048     B2      1           L  1250.16600  0.267188  0.271084  0.021902  0.221012 -0.005142  0.486552  0.001254 -6.270483e-05 -0.000703 -0.712991  0.628994 -0.220375 -0.217819 -0.125000  0.769231     0.92 -0.516159 -0.003097 -0.439893\n23049     B2      1           L  1266.81300  0.282625  0.270542  0.010285  0.236449 -0.005684  0.474935  0.000927 -3.258418e-05 -0.000698 -0.712455  0.627472 -0.227869 -0.216247 -0.416667  0.884615     0.84 -0.815188 -0.070119 -0.364069\n23050     B2      1           L  1283.48200  0.299703  0.270001 -0.002915  0.253527 -0.006226  0.461734  0.001025 -3.245744e-05 -0.000792 -0.712275  0.626998 -0.230438 -0.215491 -0.625000  1.000000     0.84 -1.047766 -0.056678 -0.329478\n23051     B2      1           L  1300.14700  0.317341  0.268058 -0.019153  0.271165 -0.008168  0.445497  0.001058 -1.165623e-04 -0.000974 -0.709937  0.627314 -0.235277 -0.217052 -0.541667  1.038462     0.92 -1.000435  0.029669 -0.396379\n23052     B2      1           L  1316.82000  0.332036  0.267420 -0.036669  0.285860 -0.008807  0.427981  0.000881 -3.830354e-05 -0.001051 -0.706107  0.629517 -0.235108 -0.223262 -0.333333  0.961538     1.00 -0.800114  0.091148 -0.452637\n23053     B2      1           L  1333.48900  0.344784  0.265995 -0.051187  0.298608 -0.010231  0.413463  0.000765 -8.547746e-05 -0.000871 -0.699364  0.633753 -0.234603 -0.232827 -0.166667  0.538462     1.00 -0.432689  0.038520 -0.227982\n23054     B2      1           L  1350.15300  0.355426  0.265479 -0.073919  0.309251 -0.010747  0.390730  0.000639 -3.096468e-05 -0.001364 -0.693339  0.637806 -0.237843 -0.236464 -0.333333  0.461539     0.92 -0.523788 -0.056586 -0.078394\n23055     B2      1           L  1366.82400  0.358737  0.265263 -0.093620  0.312561 -0.010963  0.371029  0.000199 -1.293738e-05 -0.001182 -0.691066  0.640005 -0.240222 -0.234766 -0.583333  0.500000     0.92 -0.738695 -0.057058  0.043226\n23056     B2      1           L  1383.49900  0.362587  0.266039 -0.111121  0.316411 -0.010188  0.353528  0.000231  4.651327e-05 -0.001050 -0.690284  0.640777 -0.240777 -0.234394 -0.625000  0.538462     0.96 -0.793514 -0.014668  0.040283\n23057     B2      1           L  1400.15900  0.366761  0.266047 -0.131404  0.320586 -0.010180  0.333246  0.000251  4.668901e-07 -0.001217 -0.687734  0.643374 -0.240371 -0.235187 -0.625000  0.615385     0.96 -0.846169 -0.012933 -0.024901\n23058     B2      1           L  1416.83300  0.368751  0.265928 -0.154450  0.322575 -0.010298  0.310200  0.000119 -7.117260e-06 -0.001382 -0.682392  0.647956 -0.237562 -0.240952 -0.416667  0.461539     1.00 -0.603152  0.010453 -0.042679\n23059     B2      1           L  1433.50200  0.367786  0.266618 -0.171657  0.321610 -0.009609  0.292993 -0.000058  4.138946e-05 -0.001032 -0.677830  0.651708 -0.235767 -0.245433 -0.291667  0.269231     1.04 -0.396711  0.039877  0.020778\n23060     B2      1           L  1450.16500  0.365826  0.266923 -0.194083  0.319650 -0.009304  0.270567 -0.000118  1.828242e-05 -0.001346 -0.672960  0.657183 -0.233468 -0.246432 -0.375000  0.076923     1.08 -0.348137  0.071380  0.209495\n23061     B2      1           L  1466.83900  0.369041  0.264670 -0.206930  0.322865 -0.011556  0.257720  0.000193 -1.350840e-04 -0.000770 -0.673944  0.660053 -0.231814 -0.237471 -0.541667  0.153846     1.00 -0.519711 -0.005401  0.240304\n23062     B2      1           L  1483.50900  0.354109  0.266329 -0.234304  0.307933 -0.009897  0.230346 -0.000896  9.953342e-05 -0.001642 -0.676486  0.663319 -0.228127 -0.224348 -0.750000  0.269231     0.92 -0.749502 -0.075634  0.255303\n23063     B2      1           L  1500.17400  0.347952  0.267836 -0.250284  0.301777 -0.008390  0.214365 -0.000369  9.044039e-05 -0.000959 -0.675444  0.668900 -0.220525 -0.218441 -0.583333  0.192308     0.96 -0.578963 -0.038219  0.196569\n23064     B2      1           L  1516.85700  0.343112  0.267523 -0.269539  0.296936 -0.008704  0.195110 -0.000290 -1.880176e-05 -0.001154 -0.670791  0.677326 -0.211115 -0.216100 -0.500000  0.115385     1.00 -0.484693 -0.003294  0.186983\n23065     B2      1           L  1533.51500  0.334145  0.268016 -0.285450  0.287969 -0.008210  0.179200 -0.000538  2.961633e-05 -0.000955 -0.668332  0.681534 -0.206787 -0.214670 -0.166667 -0.115385     1.12 -0.089571  0.121329  0.173466\n23066     B2      1           L  1550.17900  0.321787  0.268350 -0.303581  0.275611 -0.007876  0.161069 -0.000742  2.006427e-05 -0.001088 -0.665302  0.692088 -0.194130 -0.201744 -0.125000 -0.346154     1.12  0.057083  0.132795  0.321505\n23067     B2      1           L  1566.85100  0.304557  0.267992 -0.320148  0.258382 -0.008234  0.144501 -0.001033 -2.149729e-05 -0.000994 -0.666019  0.693953 -0.191148 -0.195730 -0.208333 -0.307692     1.08 -0.033697  0.092322  0.331925\n23068     B2      1           L  1583.51800  0.294115  0.268978 -0.334681  0.247940 -0.007249  0.129969 -0.000627  5.912188e-05 -0.000872 -0.671610  0.697977 -0.181560 -0.169716 -0.458333 -0.076923     1.00 -0.357722  0.013302  0.247469\n23069     B2      1           L  1600.18300  0.287430  0.269708 -0.342520  0.241255 -0.006518  0.122130 -0.000401  4.384588e-05 -0.000470 -0.676869  0.701177 -0.170384 -0.145495 -0.500000  0.038462     1.00 -0.439948  0.018791  0.141384\n23070     B2      1           L  1616.85500  0.268007  0.270228 -0.362152  0.221831 -0.005998  0.102498 -0.001165  3.120556e-05 -0.001178 -0.678410  0.704244 -0.161806 -0.132736 -0.416667  0.076923     0.96 -0.380270 -0.023623  0.056667\n23071     B2      1           L  1633.52700  0.259291  0.272046 -0.368608  0.213116 -0.004181  0.096042 -0.000523  1.090094e-04 -0.000387 -0.675624  0.713183 -0.144504 -0.118407 -0.041667 -0.076923     1.08  0.017883  0.083147  0.022925\n23072     B2      1           L  1650.19100  0.239615  0.271615 -0.386312  0.193439 -0.004611  0.078338 -0.001181 -2.583211e-05 -0.001062 -0.672815  0.722363 -0.123409 -0.101403  0.125000 -0.346154     1.12  0.249482  0.133694  0.205774\n23073     B2      1           L  1666.86200  0.223113  0.273575 -0.396251  0.176937 -0.002651  0.068399 -0.000990  1.175520e-04 -0.000596 -0.676442  0.725765 -0.101868 -0.072908 -0.041667 -0.192308     1.04  0.040313  0.050976  0.118926\n23074     B2      1           L  1683.53300  0.203542  0.272858 -0.410156  0.157366 -0.003368  0.054493 -0.001174 -4.299888e-05 -0.000834 -0.681805  0.724573 -0.088157 -0.048622 -0.125000 -0.038462     0.96 -0.067241 -0.033470 -0.001429\n23075     B2      1           L  1700.19500  0.189037  0.273912 -0.418042  0.142861 -0.002315  0.046608 -0.000871  6.323204e-05 -0.000473 -0.686917  0.723464 -0.065812 -0.020336 -0.083333  0.153846     0.96 -0.042940 -0.044987 -0.195756\n23076     B2      1           L  1716.86400  0.170708  0.275335 -0.429827  0.124533 -0.000892  0.034823 -0.001100  8.536420e-05 -0.000707 -0.687422  0.724372 -0.051794 -0.007331  0.041667  0.115385     1.00  0.092206 -0.011765 -0.173028\n23077     B2      1           L  1733.53800  0.155890  0.277158 -0.437038  0.109715  0.000932  0.027611 -0.000889  1.093649e-04 -0.000432 -0.684852  0.727940 -0.031998  0.007577  0.291667 -0.230769     1.04  0.356445  0.033651  0.156323\n23078     B2      1           L  1750.20000  0.139727  0.277694 -0.447256  0.093551  0.001467  0.017394 -0.000970  3.213831e-05 -0.000613 -0.681714  0.731013 -0.008207  0.028616  0.333333 -0.384615     1.00  0.375378  0.006285  0.324842\n23079     B2      1           L  1766.89800  0.122326  0.280266 -0.456208  0.076150  0.004040  0.008441 -0.001042  1.540715e-04 -0.000536 -0.680415  0.730912  0.014951  0.050792  0.375000 -0.384615     0.96  0.389654 -0.033088  0.351291\n23080     B2      1           L  1783.54200  0.109845  0.280601 -0.462796  0.063670  0.004375  0.001854 -0.000750  2.009019e-05 -0.000396 -0.679298  0.730210  0.031150  0.066165  0.375000 -0.423077     0.92  0.363675 -0.068360  0.407194\n23081     B2      1           L  1800.20600  0.093857  0.282172 -0.472300  0.047681  0.005945 -0.007650 -0.000959  9.425929e-05 -0.000570 -0.678641  0.729879  0.038300  0.072493  0.416667 -0.461539     0.96  0.391533 -0.026287  0.454767\n23082     B2      1           L  1816.87800  0.077229  0.283390 -0.480999  0.031053  0.007164 -0.016349 -0.000997  7.310435e-05 -0.000522 -0.675073  0.729482  0.062940  0.090388  0.500000 -0.423077     1.00  0.444282  0.015294  0.448092\n23083     B2      1           L  1833.54700  0.063921  0.283913 -0.486775  0.017746  0.007687 -0.022125 -0.000798  3.134871e-05 -0.000347 -0.672427  0.730339  0.073020  0.095476  0.666667 -0.423077     1.08  0.592515  0.097308  0.484438\n23084     B2      1           L  1850.21100  0.051641  0.284432 -0.492428  0.005465  0.008206 -0.027779 -0.000737  3.114196e-05 -0.000339 -0.668117  0.732585  0.084283  0.099175  0.791667 -0.423077     1.16  0.694450  0.187132  0.509695\n23085     B2      1           L  1866.88300  0.040971  0.284699 -0.495705 -0.005205  0.008472 -0.031055 -0.000640  1.599694e-05 -0.000197 -0.667312  0.732845  0.087042  0.100286  0.750000 -0.384615     1.12  0.657521  0.146538  0.466846\n23086     B2      1           L  1883.55200  0.029840  0.285829 -0.498527 -0.016336  0.009603 -0.033878 -0.000668  6.782150e-05 -0.000169 -0.668266  0.731234  0.090907  0.102244  0.500000 -0.192308     1.08  0.459706  0.091095  0.227076\n23087     B2      1           L  1900.21600  0.021282  0.286547 -0.498999 -0.024894  0.010321 -0.034350 -0.000514  4.309047e-05 -0.000028 -0.673125  0.726405  0.093878  0.102106  0.291667  0.000000     0.96  0.301523 -0.043103  0.010092\n"
     ]
    }
   ],
   "source": [
    "dfs = dict(tuple(dataframe.groupby('tester')))\n",
    "grouped = dict()\n",
    "    \n",
    "for k, v in dfs.items():\n",
    "    d = dict(tuple(v.groupby(['trial', 'tester'])))\n",
    "    grouped.update(d)\n",
    "    \n",
    "    #print(v, '\\n\\n')\n",
    "    print(k, v['trial'].unique())\n",
    "    \n",
    "    \n",
    "# so this is the batch generating I guess\n",
    "# they are also were ordered alphabetically\n",
    "# as you can see they are grouped by ['tester'] B1, ..., Y3\n",
    "# each tester have 10 ['trial']\n",
    "\n",
    "# there is an interesting issue when turning this to dict()(grouped) \n",
    "# they are being appended to grouped \n",
    "# BUT THEY ALL HAVE THE SAME KEYS SO IT IS OVERRIDING THE DICTIONARY WITH THE SAME KEYS\n",
    "# FFS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([(1, 'B1'), (2, 'B1'), (3, 'B1'), (4, 'B1'), (5, 'B1'), (6, 'B1'), (7, 'B1'), (8, 'B1'), (9, 'B1'), (10, 'B1'), (1, 'B2'), (2, 'B2'), (3, 'B2'), (4, 'B2'), (5, 'B2'), (6, 'B2'), (7, 'B2'), (8, 'B2'), (9, 'B2'), (10, 'B2'), (1, 'C1'), (2, 'C1'), (3, 'C1'), (4, 'C1'), (5, 'C1'), (6, 'C1'), (7, 'C1'), (8, 'C1'), (9, 'C1'), (10, 'C1'), (1, 'C2'), (2, 'C2'), (3, 'C2'), (4, 'C2'), (5, 'C2'), (6, 'C2'), (7, 'C2'), (8, 'C2'), (9, 'C2'), (10, 'C2'), (1, 'D1'), (2, 'D1'), (3, 'D1'), (4, 'D1'), (5, 'D1'), (6, 'D1'), (7, 'D1'), (8, 'D1'), (9, 'D1'), (10, 'D1'), (1, 'D2'), (2, 'D2'), (3, 'D2'), (4, 'D2'), (5, 'D2'), (6, 'D2'), (7, 'D2'), (8, 'D2'), (9, 'D2'), (10, 'D2'), (1, 'F1'), (2, 'F1'), (3, 'F1'), (4, 'F1'), (5, 'F1'), (6, 'F1'), (7, 'F1'), (8, 'F1'), (9, 'F1'), (10, 'F1'), (1, 'J1'), (2, 'J1'), (3, 'J1'), (4, 'J1'), (5, 'J1'), (6, 'J1'), (7, 'J1'), (8, 'J1'), (9, 'J1'), (10, 'J1'), (1, 'J2'), (2, 'J2'), (3, 'J2'), (4, 'J2'), (5, 'J2'), (6, 'J2'), (7, 'J2'), (8, 'J2'), (9, 'J2'), (10, 'J2'), (1, 'J3'), (2, 'J3'), (3, 'J3'), (4, 'J3'), (5, 'J3'), (6, 'J3'), (7, 'J3'), (8, 'J3'), (9, 'J3'), (10, 'J3'), (1, 'J4'), (2, 'J4'), (3, 'J4'), (4, 'J4'), (5, 'J4'), (6, 'J4'), (7, 'J4'), (8, 'J4'), (9, 'J4'), (10, 'J4'), (1, 'J5'), (2, 'J5'), (3, 'J5'), (4, 'J5'), (5, 'J5'), (6, 'J5'), (7, 'J5'), (8, 'J5'), (9, 'J5'), (10, 'J5'), (1, 'M1'), (2, 'M1'), (3, 'M1'), (4, 'M1'), (5, 'M1'), (6, 'M1'), (7, 'M1'), (8, 'M1'), (9, 'M1'), (10, 'M1'), (1, 'M2'), (2, 'M2'), (3, 'M2'), (4, 'M2'), (5, 'M2'), (6, 'M2'), (7, 'M2'), (8, 'M2'), (9, 'M2'), (10, 'M2'), (1, 'M3'), (2, 'M3'), (3, 'M3'), (4, 'M3'), (5, 'M3'), (6, 'M3'), (7, 'M3'), (8, 'M3'), (9, 'M3'), (10, 'M3'), (1, 'R1'), (2, 'R1'), (3, 'R1'), (4, 'R1'), (5, 'R1'), (6, 'R1'), (7, 'R1'), (8, 'R1'), (9, 'R1'), (10, 'R1'), (1, 'R2'), (2, 'R2'), (3, 'R2'), (4, 'R2'), (5, 'R2'), (6, 'R2'), (7, 'R2'), (8, 'R2'), (9, 'R2'), (10, 'R2'), (1, 'S1'), (2, 'S1'), (3, 'S1'), (4, 'S1'), (5, 'S1'), (6, 'S1'), (7, 'S1'), (8, 'S1'), (9, 'S1'), (10, 'S1'), (1, 'S2'), (2, 'S2'), (3, 'S2'), (4, 'S2'), (5, 'S2'), (6, 'S2'), (7, 'S2'), (8, 'S2'), (9, 'S2'), (10, 'S2'), (1, 'S3'), (2, 'S3'), (3, 'S3'), (4, 'S3'), (5, 'S3'), (6, 'S3'), (7, 'S3'), (8, 'S3'), (9, 'S3'), (10, 'S3'), (1, 'T1'), (2, 'T1'), (3, 'T1'), (4, 'T1'), (5, 'T1'), (6, 'T1'), (7, 'T1'), (8, 'T1'), (9, 'T1'), (10, 'T1'), (1, 'T2'), (2, 'T2'), (3, 'T2'), (4, 'T2'), (5, 'T2'), (6, 'T2'), (7, 'T2'), (8, 'T2'), (9, 'T2'), (10, 'T2'), (1, 'U1'), (2, 'U1'), (3, 'U1'), (4, 'U1'), (5, 'U1'), (6, 'U1'), (7, 'U1'), (8, 'U1'), (9, 'U1'), (10, 'U1'), (1, 'W1'), (2, 'W1'), (3, 'W1'), (4, 'W1'), (5, 'W1'), (6, 'W1'), (7, 'W1'), (8, 'W1'), (9, 'W1'), (10, 'W1'), (1, 'W2'), (2, 'W2'), (3, 'W2'), (4, 'W2'), (5, 'W2'), (6, 'W2'), (7, 'W2'), (8, 'W2'), (9, 'W2'), (10, 'W2'), (1, 'Y1'), (2, 'Y1'), (3, 'Y1'), (4, 'Y1'), (5, 'Y1'), (6, 'Y1'), (7, 'Y1'), (8, 'Y1'), (9, 'Y1'), (10, 'Y1'), (1, 'Y2'), (2, 'Y2'), (3, 'Y2'), (4, 'Y2'), (5, 'Y2'), (6, 'Y2'), (7, 'Y2'), (8, 'Y2'), (9, 'Y2'), (10, 'Y2'), (1, 'Y3'), (2, 'Y3'), (3, 'Y3'), (4, 'Y3'), (5, 'Y3'), (6, 'Y3'), (7, 'Y3'), (8, 'Y3'), (9, 'Y3'), (10, 'Y3')]) \n\n280 \n\n      tester  trial rightHanded   timestamp      posX      posY      posZ   posRelX   posRelY   posRelZ      velX          velY      velZ     quatW     quatX     quatY     quatZ   accRelX   accRelY  accRelZ   accAbsX   accAbsY   accAbsZ\n22974     B2      1           L    16.66000  0.046176  0.276226 -0.464650  0.000000  0.000000  0.000000  0.000000  0.000000e+00  0.000000 -0.702897  0.708961  0.028066  0.050223 -0.041667  0.038462     0.96 -0.006658 -0.039619 -0.049389\n22975     B2      1           L    33.32500  0.046074  0.276587 -0.465288 -0.000102  0.000360 -0.000638 -0.000006  2.161540e-05 -0.000038 -0.703015  0.708776  0.026372  0.052079 -0.083333  0.000000     1.00 -0.046020  0.002293 -0.015358\n22976     B2      1           L    49.99500  0.045457  0.276681 -0.465823 -0.000719  0.000454 -0.001173 -0.000037  5.654752e-06 -0.000032 -0.703015  0.708776  0.026372  0.052079 -0.083333  0.000000     1.00 -0.046020  0.002293 -0.015358\n22977     B2      1           L    66.66600  0.045431  0.276679 -0.465889 -0.000745  0.000453 -0.001239 -0.000002 -1.144112e-07 -0.000004 -0.705571  0.706068  0.028408  0.053191 -0.083333  0.076923     1.00 -0.038842  0.002088 -0.084691\n22978     B2      1           L    83.33401  0.045204  0.276640 -0.466186 -0.000971  0.000414 -0.001536 -0.000014 -2.319030e-06 -0.000018 -0.705773  0.705807  0.028492  0.053943 -0.166667  0.115385     1.00 -0.116072  0.005092 -0.131945\n22979     B2      1           L   100.00300  0.044031  0.276621 -0.467819 -0.002144  0.000395 -0.003170 -0.000070 -1.147825e-06 -0.000098 -0.705881  0.705271  0.030153  0.058443 -0.166667  0.038462     1.00 -0.120548  0.005798 -0.055628\n22980     B2      1           L   116.67100  0.043771  0.276433 -0.467986 -0.002405  0.000206 -0.003336 -0.000016 -1.130908e-05 -0.000010 -0.705881  0.705271  0.030153  0.058443 -0.166667  0.038462     1.00 -0.120548  0.005798 -0.055628\n22981     B2      1           L   133.33800  0.042781  0.276837 -0.469208 -0.003395  0.000610 -0.004558 -0.000059  2.424131e-05 -0.000073 -0.701492  0.709037  0.032668  0.064099 -0.208333 -0.115385     1.00 -0.176835  0.009618  0.078212\n22982     B2      1           L   150.00800  0.042138  0.276817 -0.470323 -0.004037  0.000591 -0.005673 -0.000039 -1.158483e-06 -0.000067 -0.699122  0.710853  0.035607  0.068185 -0.250000 -0.192308     0.96 -0.229845 -0.026141  0.140895\n22983     B2      1           L   166.67900  0.039595  0.276719 -0.473156 -0.006581  0.000492 -0.008506 -0.000153 -5.918993e-06 -0.000170 -0.697881  0.711441  0.039428  0.072515 -0.250000 -0.192308     0.96 -0.230624 -0.025562  0.135519\n22984     B2      1           L   183.35900  0.036453  0.276665 -0.474754 -0.009723  0.000439 -0.010105 -0.000188 -3.226796e-06 -0.000096 -0.696812  0.711478  0.045775  0.078462 -0.250000 -0.192308     0.92 -0.235402 -0.065375  0.130173\n22985     B2      1           L   200.01300  0.033984  0.276621 -0.476795 -0.012191  0.000395 -0.012145 -0.000148 -2.639510e-06 -0.000123 -0.696234  0.711514  0.049063  0.081233 -0.291667 -0.269231     0.92 -0.292167 -0.061619  0.195022\n22986     B2      1           L   216.68400  0.031747  0.276729 -0.477728 -0.014429  0.000502 -0.013078 -0.000134  6.460659e-06 -0.000056 -0.694752  0.711566  0.057938  0.087389 -0.250000 -0.230769     0.96 -0.249446 -0.024916  0.156022\n22987     B2      1           L   233.35000  0.026647  0.276650 -0.477661 -0.019529  0.000423 -0.013012 -0.000306 -4.733393e-06  0.000004 -0.694113  0.711678  0.061012  0.089438 -0.208333 -0.230769     1.00 -0.209539  0.013343  0.160891\n22988     B2      1           L   250.02100  0.022670  0.276057 -0.477260 -0.023506 -0.000169 -0.012610 -0.000239 -3.554611e-05  0.000024 -0.692165  0.711904  0.070123  0.095829 -0.166667 -0.230769     1.00 -0.176252  0.011799  0.161957\n22989     B2      1           L   266.68900  0.015826  0.276280 -0.476019 -0.030350  0.000054 -0.011369 -0.000411  1.338493e-05  0.000074 -0.690886  0.711006  0.079976  0.103684 -0.125000 -0.230769     1.00 -0.143089  0.010240  0.166796\n22990     B2      1           L   283.36000  0.009658  0.275564 -0.475491 -0.036518 -0.000662 -0.010841 -0.000370 -4.295248e-05  0.000032 -0.690748  0.708305  0.090666  0.113804 -0.166667 -0.153846     1.00 -0.167595  0.008460  0.079789\n22991     B2      1           L   300.02600  0.001912  0.274828 -0.473538 -0.044264 -0.001398 -0.008888 -0.000465 -4.414560e-05  0.000117 -0.690148  0.706998  0.097531  0.119734 -0.166667 -0.153846     1.00 -0.170678  0.008147  0.077168\n22992     B2      1           L   316.69600 -0.006702  0.274787 -0.471547 -0.052878 -0.001440 -0.006897 -0.000517 -2.510043e-06  0.000119 -0.687361  0.707140  0.106830  0.126786 -0.125000 -0.192308     1.04 -0.146954  0.048281  0.117129\n22993     B2      1           L   333.36300 -0.015558  0.274564 -0.470000 -0.061734 -0.001663 -0.005350 -0.000531 -1.337502e-05  0.000093 -0.686123  0.707465  0.110059  0.128900 -0.083333 -0.192308     1.04 -0.109898  0.047505  0.127206\n22994     B2      1           L   350.02800 -0.024582  0.273761 -0.467359 -0.070758 -0.002466 -0.002709 -0.000542 -4.818441e-05  0.000158 -0.682816  0.707880  0.120113  0.135059  0.000000 -0.269231     1.04 -0.067172  0.049526  0.219247\n22995     B2      1           L   366.70300 -0.034642  0.273023 -0.463970 -0.080818 -0.003203  0.000679 -0.000603 -4.424151e-05  0.000203 -0.680824  0.706134  0.131306  0.143568  0.000000 -0.269231     1.00 -0.078594  0.009567  0.216983\n22996     B2      1           L   383.37100 -0.043691  0.272807 -0.460077 -0.089867 -0.003420  0.004573 -0.000543 -1.297010e-05  0.000234 -0.680025  0.704449  0.137806  0.149423 -0.083333 -0.230769     1.00 -0.145050  0.008598  0.147952\n22997     B2      1           L   400.03700 -0.055371  0.273220 -0.455605 -0.101546 -0.003006  0.009045 -0.000701  2.479535e-05  0.000268 -0.678387  0.703453  0.145257  0.154420  0.000000 -0.192308     1.00 -0.059417  0.006477  0.143025\n22998     B2      1           L   416.70700 -0.066380  0.273998 -0.449916 -0.112556 -0.002229  0.014734 -0.000660  4.665928e-05  0.000341 -0.675100  0.703970  0.153923  0.158029  0.041667 -0.230769     1.04 -0.046384  0.048738  0.185977\n22999     B2      1           L   433.39300 -0.077091  0.273701 -0.444537 -0.123267 -0.002525  0.020112 -0.000642 -1.777676e-05  0.000322 -0.670882  0.705939  0.161313  0.159829  0.083333 -0.192308     1.04 -0.000716  0.049018  0.158387\n23000     B2      1           L   450.04400 -0.089340  0.273588 -0.438633 -0.135516 -0.002639  0.026016 -0.000736 -6.819220e-06  0.000355 -0.668747  0.707136  0.164312  0.160426  0.125000 -0.269231     1.00 -0.001397  0.014618  0.242193\n23001     B2      1           L   466.71400 -0.101809  0.272931 -0.432776 -0.147985 -0.003295  0.031874 -0.000748 -3.939731e-05  0.000351 -0.664090  0.710080  0.170509  0.160306  0.208333 -0.346154     1.00  0.029184  0.024579  0.335575\n23002     B2      1           L   483.39700 -0.114633  0.272429 -0.425850 -0.160808 -0.003798  0.038800 -0.000769 -3.009526e-05  0.000415 -0.661953  0.710371  0.177803  0.159931  0.333333 -0.307692     1.04  0.143830  0.069443  0.350700\n23003     B2      1           L   500.04900 -0.127303  0.272556 -0.418219 -0.173479 -0.003671  0.046431 -0.000761  7.604505e-06  0.000458 -0.661915  0.709357  0.181691  0.160217  0.333333 -0.192308     1.00  0.190628  0.023610  0.252939\n23004     B2      1           L   516.71700 -0.139577  0.272501 -0.410628 -0.185753 -0.003725  0.054022 -0.000736 -3.264875e-06  0.000455 -0.661789  0.708725  0.185103  0.159627  0.208333 -0.153846     0.96  0.092585 -0.023548  0.163220\n23005     B2      1           L   533.38900 -0.151437  0.272624 -0.400840 -0.197613 -0.003602  0.063809 -0.000711  7.377291e-06  0.000587 -0.661789  0.708725  0.185103  0.159627  0.208333 -0.153846     0.96  0.092585 -0.023548  0.163220\n23006     B2      1           L   550.05600 -0.164111  0.272932 -0.389769 -0.210286 -0.003295  0.074880 -0.000760  1.846218e-05  0.000664 -0.661686  0.708339  0.191080  0.154647  0.375000 -0.076923     1.00  0.259329  0.025210  0.168033\n23007     B2      1           L   566.72500 -0.178487  0.272788 -0.377576 -0.224663 -0.003438  0.087073 -0.000862 -8.601530e-06  0.000731 -0.663755  0.706448  0.193313  0.151626  0.333333  0.000000     0.96  0.252396 -0.019469  0.086989\n23008     B2      1           L   583.39800 -0.188321  0.272749 -0.366179 -0.234497 -0.003477  0.098471 -0.000590 -2.330851e-06  0.000684 -0.664629  0.705797  0.193965  0.149989  0.333333  0.038462     0.96  0.267191 -0.020263  0.053989\n23009     B2      1           L   600.06300 -0.198577  0.272840 -0.354137 -0.244753 -0.003386  0.110513 -0.000615  5.422167e-06  0.000723 -0.666115  0.705333  0.195340  0.143662  0.416667  0.038462     0.96  0.330354 -0.010365  0.090440\n23010     B2      1           L   616.73400 -0.211027  0.272010 -0.339649 -0.257202 -0.004216  0.125001 -0.000747 -4.974752e-05  0.000869 -0.666617  0.707283  0.194952  0.131781  0.583333  0.038462     1.00  0.462592  0.051379  0.149556\n23011     B2      1           L   633.40410 -0.221438  0.271820 -0.327228 -0.267614 -0.004406  0.137422 -0.000625 -1.142032e-05  0.000745 -0.666953  0.707862  0.194529  0.127533  0.666667 -0.038462     1.04  0.495302  0.105112  0.246832\n23012     B2      1           L   650.06900 -0.231581  0.272001 -0.312575 -0.277757 -0.004226  0.152075 -0.000609  1.082828e-05  0.000879 -0.670113  0.707253  0.192388  0.117168  0.750000  0.038462     1.08  0.590916  0.157655  0.202566\n23013     B2      1           L   666.74100 -0.238708  0.271008 -0.300022 -0.284884 -0.005219  0.164628 -0.000427 -5.955996e-05  0.000753 -0.675992  0.704543  0.187277  0.107614  0.666667  0.115385     1.08  0.542016  0.149360  0.096692\n23014     B2      1           L   683.40800 -0.248256  0.269541 -0.284728 -0.294432 -0.006686  0.179921 -0.000573 -8.802837e-05  0.000918 -0.680782  0.702092  0.182901  0.100743  0.666667  0.192308     1.08  0.568125  0.150806  0.026587\n23015     B2      1           L   700.07000 -0.252823  0.269787 -0.269877 -0.298999 -0.006439  0.194773 -0.000274  1.480101e-05  0.000891 -0.686201  0.700481  0.174738  0.089001  0.750000  0.230769     1.12  0.648058  0.204180  0.011200\n23016     B2      1           L   716.74510 -0.258521  0.270667 -0.250517 -0.304697 -0.005559  0.214133 -0.000342  5.277542e-05  0.001161 -0.687601  0.700228  0.172051  0.085344  0.708333  0.153846     1.08  0.584754  0.159985  0.065597\n23017     B2      1           L   733.41800 -0.260742  0.270934 -0.231301 -0.306918 -0.005292  0.233349 -0.000133  1.603175e-05  0.001153 -0.692891  0.698661  0.162864  0.072457  0.666667  0.115385     1.00  0.537696  0.078098  0.079664\n23018     B2      1           L   750.08200 -0.262827  0.270249 -0.216254 -0.309003 -0.005977  0.248396 -0.000125 -4.111053e-05  0.000903 -0.699283  0.695606  0.153611  0.059489  0.708333  0.192308     1.00  0.594915  0.088413  0.012296\n23019     B2      1           L   766.76400 -0.262126  0.270943 -0.199324 -0.308301 -0.005284  0.265325  0.000042  4.155387e-05  0.001015 -0.706894  0.691561  0.141714  0.044285  0.708333  0.192308     1.00  0.587737  0.092371  0.003016\n23020     B2      1           L   783.42210 -0.263789  0.273021 -0.180260 -0.309964 -0.003205  0.284390 -0.000100  1.247910e-04  0.001144 -0.709423  0.690663  0.135439  0.036879  0.791667  0.269231     1.04  0.678051  0.147860 -0.059029\n23021     B2      1           L   800.08610 -0.260532  0.273995 -0.160662 -0.306707 -0.002231  0.303988  0.000195  5.842785e-05  0.001176 -0.713051  0.689807  0.123243  0.023162  0.791667  0.192308     0.96  0.667768  0.067410 -0.006406\n23022     B2      1           L   816.75600 -0.251356  0.273994 -0.140008 -0.297532 -0.002232  0.324642  0.000550 -3.039232e-08  0.001239 -0.716429  0.688231  0.113574  0.012956  0.833333  0.230769     0.96  0.712810  0.076401 -0.050615\n23023     B2      1           L   833.42800 -0.244854  0.275998 -0.120201 -0.291029 -0.000229  0.344448  0.000390  1.201549e-04  0.001188 -0.721090  0.685619  0.099775  0.000114  0.750000  0.307692     0.92  0.644976  0.030609 -0.159452\n23024     B2      1           L   850.09200 -0.240180  0.277547 -0.103671 -0.286355  0.001321  0.360978  0.000280  9.300168e-05  0.000992 -0.725020  0.682853  0.089233 -0.009752  0.708333  0.307692     0.88  0.604481 -0.013162 -0.177663\n23025     B2      1           L   866.76400 -0.227272  0.278597 -0.081270 -0.273448  0.002371  0.383380  0.000774  6.297779e-05  0.001344 -0.730442  0.678524  0.074098 -0.023865  0.750000  0.423077     0.84  0.650569 -0.035731 -0.306659\n23026     B2      1           L   883.44310 -0.216680  0.280669 -0.063762 -0.262856  0.004442  0.400887  0.000635  1.241944e-04  0.001050 -0.736276  0.673306  0.053268 -0.041450  0.791667  0.461539     0.88  0.671243  0.015208 -0.364610\n23027     B2      1           L   900.09700 -0.201147  0.281223 -0.042198 -0.247323  0.004997  0.422451  0.000933  3.329186e-05  0.001295 -0.738236  0.671340  0.046162 -0.046678  0.750000  0.538462     0.88  0.624669  0.017400 -0.448917\n23028     B2      1           L   916.76900 -0.176389  0.281599 -0.019837 -0.222565  0.005373  0.444812  0.001485  2.254659e-05  0.001341 -0.745361  0.663363  0.018178 -0.063693  0.666667  0.653846     0.88  0.516294  0.020653 -0.581436\n23029     B2      1           L   933.44010 -0.164708  0.281935 -0.007719 -0.210884  0.005708  0.456931  0.000701  2.012204e-05  0.000727 -0.749245  0.658108 -0.002969 -0.074284  0.500000  0.730769     0.84  0.331880 -0.027842 -0.659082\n23030     B2      1           L   950.10410 -0.151946  0.283721  0.004287 -0.198122  0.007494  0.468936  0.000766  1.071803e-04  0.000720 -0.750085  0.656702 -0.009305 -0.077637  0.416667  0.769231     0.80  0.242171 -0.070791 -0.695162\n23031     B2      1           L   966.77700 -0.120253  0.281845  0.031154 -0.166429  0.005618  0.495804  0.001901 -1.125118e-04  0.001611 -0.751375  0.653115 -0.029362 -0.089515  0.375000  0.769231     0.76  0.180033 -0.113369 -0.701009\n23032     B2      1           L   983.44700 -0.099263  0.283890  0.040987 -0.145439  0.007663  0.505637  0.001259  1.226562e-04  0.000590 -0.751106  0.650486 -0.048373 -0.101823  0.291667  0.730769     0.76  0.081037 -0.126415 -0.653433\n23033     B2      1           L  1000.11100 -0.080633  0.283744  0.049306 -0.126809  0.007518  0.513956  0.001118 -8.734668e-06  0.000499 -0.749881  0.648256 -0.065003 -0.114964  0.291667  0.807692     0.76  0.034972 -0.116538 -0.730279\n23034     B2      1           L  1016.78200 -0.060791  0.283845  0.055696 -0.106967  0.007619  0.520345  0.001190  6.076298e-06  0.000383 -0.747991  0.647432 -0.075939 -0.124797  0.250000  0.769231     0.80 -0.018315 -0.087512 -0.679152\n23035     B2      1           L  1033.45000 -0.033489  0.283755  0.067249 -0.079665  0.007529  0.531899  0.001638 -5.414042e-06  0.000693 -0.744638  0.646716 -0.089865 -0.138552  0.250000  0.730769     0.84 -0.037479 -0.056083 -0.640108\n23036     B2      1           L  1050.11600 -0.007844  0.283641  0.072779 -0.054020  0.007415  0.537428  0.001539 -6.818441e-06  0.000332 -0.743525  0.646567 -0.093735 -0.142601  0.291667  0.730769     0.88 -0.008473 -0.013824 -0.648751\n23037     B2      1           L  1066.78900  0.014907  0.281962  0.076757 -0.031269  0.005736  0.541407  0.001365 -1.007200e-04  0.000239 -0.739362  0.645910 -0.107453 -0.156839  0.333333  0.692308     0.92  0.012360  0.021346 -0.627297\n23038     B2      1           L  1083.47300  0.037915  0.282031  0.079259 -0.008260  0.005805  0.543909  0.001379  4.145969e-06  0.000150 -0.735627  0.644910 -0.121726 -0.167707  0.375000  0.692308     0.92  0.029032  0.021624 -0.649427\n23039     B2      1           L  1100.12200  0.061196  0.280756  0.081691  0.015020  0.004529  0.546341  0.001398 -7.660798e-05  0.000146 -0.733883  0.643397 -0.132683 -0.172773  0.208333  0.576923     0.84 -0.079407 -0.086132 -0.490289\n23040     B2      1           L  1116.79400  0.088260  0.280200  0.079902  0.042084  0.003974  0.544552  0.001623 -3.331489e-05 -0.000107 -0.733213  0.641100 -0.143304 -0.175650  0.166667  0.653846     0.84 -0.151681 -0.079674 -0.539339\n23041     B2      1           L  1133.49000  0.109642  0.279459  0.078112  0.063466  0.003232  0.542762  0.001281 -4.441241e-05 -0.000107 -0.732269  0.637575 -0.158459 -0.179360  0.125000  0.730769     0.80 -0.226250 -0.110313 -0.588996\n23042     B2      1           L  1150.13100  0.137403  0.279318  0.070889  0.091227  0.003092  0.535539  0.001668 -8.429757e-06 -0.000434 -0.730940  0.635211 -0.170024 -0.182554 -0.125000  0.807692     0.76 -0.486813 -0.151382 -0.537076\n23043     B2      1           L  1166.80200  0.159276  0.278893  0.066603  0.113100  0.002667  0.531253  0.001312 -2.550312e-05 -0.000257 -0.728513  0.634202 -0.178843 -0.187273 -0.166667  0.807692     0.80 -0.529492 -0.113532 -0.503941\n23044     B2      1           L  1183.49100  0.186099  0.277714  0.058907  0.139923  0.001488  0.523556  0.001607 -7.064376e-05 -0.000461 -0.724111  0.633689 -0.188647 -0.196249 -0.208333  0.769231     0.80 -0.560411 -0.123797 -0.439689\n23045     B2      1           L  1200.13500  0.209720  0.275478  0.050442  0.163544 -0.000749  0.515092  0.001419 -1.343868e-04 -0.000509 -0.722868  0.633489 -0.191050 -0.199133 -0.083333  0.730769     0.92 -0.435915 -0.004943 -0.455201\n23046     B2      1           L  1216.80900  0.228177  0.273738  0.042620  0.182001 -0.002488  0.507270  0.001107 -1.043237e-04 -0.000469 -0.718538  0.632339 -0.199657 -0.209732  0.083333  0.807692     1.04 -0.355479  0.126962 -0.586943\n23047     B2      1           L  1233.47700  0.246259  0.272131  0.033639  0.200083 -0.004096  0.498288  0.001085 -9.643575e-05 -0.000539 -0.715415  0.630247 -0.209776 -0.216711  0.041667  0.807692     1.00 -0.402940  0.084779 -0.561245\n23048     B2      1           L  1250.16600  0.267188  0.271084  0.021902  0.221012 -0.005142  0.486552  0.001254 -6.270483e-05 -0.000703 -0.712991  0.628994 -0.220375 -0.217819 -0.125000  0.769231     0.92 -0.516159 -0.003097 -0.439893\n23049     B2      1           L  1266.81300  0.282625  0.270542  0.010285  0.236449 -0.005684  0.474935  0.000927 -3.258418e-05 -0.000698 -0.712455  0.627472 -0.227869 -0.216247 -0.416667  0.884615     0.84 -0.815188 -0.070119 -0.364069\n23050     B2      1           L  1283.48200  0.299703  0.270001 -0.002915  0.253527 -0.006226  0.461734  0.001025 -3.245744e-05 -0.000792 -0.712275  0.626998 -0.230438 -0.215491 -0.625000  1.000000     0.84 -1.047766 -0.056678 -0.329478\n23051     B2      1           L  1300.14700  0.317341  0.268058 -0.019153  0.271165 -0.008168  0.445497  0.001058 -1.165623e-04 -0.000974 -0.709937  0.627314 -0.235277 -0.217052 -0.541667  1.038462     0.92 -1.000435  0.029669 -0.396379\n23052     B2      1           L  1316.82000  0.332036  0.267420 -0.036669  0.285860 -0.008807  0.427981  0.000881 -3.830354e-05 -0.001051 -0.706107  0.629517 -0.235108 -0.223262 -0.333333  0.961538     1.00 -0.800114  0.091148 -0.452637\n23053     B2      1           L  1333.48900  0.344784  0.265995 -0.051187  0.298608 -0.010231  0.413463  0.000765 -8.547746e-05 -0.000871 -0.699364  0.633753 -0.234603 -0.232827 -0.166667  0.538462     1.00 -0.432689  0.038520 -0.227982\n23054     B2      1           L  1350.15300  0.355426  0.265479 -0.073919  0.309251 -0.010747  0.390730  0.000639 -3.096468e-05 -0.001364 -0.693339  0.637806 -0.237843 -0.236464 -0.333333  0.461539     0.92 -0.523788 -0.056586 -0.078394\n23055     B2      1           L  1366.82400  0.358737  0.265263 -0.093620  0.312561 -0.010963  0.371029  0.000199 -1.293738e-05 -0.001182 -0.691066  0.640005 -0.240222 -0.234766 -0.583333  0.500000     0.92 -0.738695 -0.057058  0.043226\n23056     B2      1           L  1383.49900  0.362587  0.266039 -0.111121  0.316411 -0.010188  0.353528  0.000231  4.651327e-05 -0.001050 -0.690284  0.640777 -0.240777 -0.234394 -0.625000  0.538462     0.96 -0.793514 -0.014668  0.040283\n23057     B2      1           L  1400.15900  0.366761  0.266047 -0.131404  0.320586 -0.010180  0.333246  0.000251  4.668901e-07 -0.001217 -0.687734  0.643374 -0.240371 -0.235187 -0.625000  0.615385     0.96 -0.846169 -0.012933 -0.024901\n23058     B2      1           L  1416.83300  0.368751  0.265928 -0.154450  0.322575 -0.010298  0.310200  0.000119 -7.117260e-06 -0.001382 -0.682392  0.647956 -0.237562 -0.240952 -0.416667  0.461539     1.00 -0.603152  0.010453 -0.042679\n23059     B2      1           L  1433.50200  0.367786  0.266618 -0.171657  0.321610 -0.009609  0.292993 -0.000058  4.138946e-05 -0.001032 -0.677830  0.651708 -0.235767 -0.245433 -0.291667  0.269231     1.04 -0.396711  0.039877  0.020778\n23060     B2      1           L  1450.16500  0.365826  0.266923 -0.194083  0.319650 -0.009304  0.270567 -0.000118  1.828242e-05 -0.001346 -0.672960  0.657183 -0.233468 -0.246432 -0.375000  0.076923     1.08 -0.348137  0.071380  0.209495\n23061     B2      1           L  1466.83900  0.369041  0.264670 -0.206930  0.322865 -0.011556  0.257720  0.000193 -1.350840e-04 -0.000770 -0.673944  0.660053 -0.231814 -0.237471 -0.541667  0.153846     1.00 -0.519711 -0.005401  0.240304\n23062     B2      1           L  1483.50900  0.354109  0.266329 -0.234304  0.307933 -0.009897  0.230346 -0.000896  9.953342e-05 -0.001642 -0.676486  0.663319 -0.228127 -0.224348 -0.750000  0.269231     0.92 -0.749502 -0.075634  0.255303\n23063     B2      1           L  1500.17400  0.347952  0.267836 -0.250284  0.301777 -0.008390  0.214365 -0.000369  9.044039e-05 -0.000959 -0.675444  0.668900 -0.220525 -0.218441 -0.583333  0.192308     0.96 -0.578963 -0.038219  0.196569\n23064     B2      1           L  1516.85700  0.343112  0.267523 -0.269539  0.296936 -0.008704  0.195110 -0.000290 -1.880176e-05 -0.001154 -0.670791  0.677326 -0.211115 -0.216100 -0.500000  0.115385     1.00 -0.484693 -0.003294  0.186983\n23065     B2      1           L  1533.51500  0.334145  0.268016 -0.285450  0.287969 -0.008210  0.179200 -0.000538  2.961633e-05 -0.000955 -0.668332  0.681534 -0.206787 -0.214670 -0.166667 -0.115385     1.12 -0.089571  0.121329  0.173466\n23066     B2      1           L  1550.17900  0.321787  0.268350 -0.303581  0.275611 -0.007876  0.161069 -0.000742  2.006427e-05 -0.001088 -0.665302  0.692088 -0.194130 -0.201744 -0.125000 -0.346154     1.12  0.057083  0.132795  0.321505\n23067     B2      1           L  1566.85100  0.304557  0.267992 -0.320148  0.258382 -0.008234  0.144501 -0.001033 -2.149729e-05 -0.000994 -0.666019  0.693953 -0.191148 -0.195730 -0.208333 -0.307692     1.08 -0.033697  0.092322  0.331925\n23068     B2      1           L  1583.51800  0.294115  0.268978 -0.334681  0.247940 -0.007249  0.129969 -0.000627  5.912188e-05 -0.000872 -0.671610  0.697977 -0.181560 -0.169716 -0.458333 -0.076923     1.00 -0.357722  0.013302  0.247469\n23069     B2      1           L  1600.18300  0.287430  0.269708 -0.342520  0.241255 -0.006518  0.122130 -0.000401  4.384588e-05 -0.000470 -0.676869  0.701177 -0.170384 -0.145495 -0.500000  0.038462     1.00 -0.439948  0.018791  0.141384\n23070     B2      1           L  1616.85500  0.268007  0.270228 -0.362152  0.221831 -0.005998  0.102498 -0.001165  3.120556e-05 -0.001178 -0.678410  0.704244 -0.161806 -0.132736 -0.416667  0.076923     0.96 -0.380270 -0.023623  0.056667\n23071     B2      1           L  1633.52700  0.259291  0.272046 -0.368608  0.213116 -0.004181  0.096042 -0.000523  1.090094e-04 -0.000387 -0.675624  0.713183 -0.144504 -0.118407 -0.041667 -0.076923     1.08  0.017883  0.083147  0.022925\n23072     B2      1           L  1650.19100  0.239615  0.271615 -0.386312  0.193439 -0.004611  0.078338 -0.001181 -2.583211e-05 -0.001062 -0.672815  0.722363 -0.123409 -0.101403  0.125000 -0.346154     1.12  0.249482  0.133694  0.205774\n23073     B2      1           L  1666.86200  0.223113  0.273575 -0.396251  0.176937 -0.002651  0.068399 -0.000990  1.175520e-04 -0.000596 -0.676442  0.725765 -0.101868 -0.072908 -0.041667 -0.192308     1.04  0.040313  0.050976  0.118926\n23074     B2      1           L  1683.53300  0.203542  0.272858 -0.410156  0.157366 -0.003368  0.054493 -0.001174 -4.299888e-05 -0.000834 -0.681805  0.724573 -0.088157 -0.048622 -0.125000 -0.038462     0.96 -0.067241 -0.033470 -0.001429\n23075     B2      1           L  1700.19500  0.189037  0.273912 -0.418042  0.142861 -0.002315  0.046608 -0.000871  6.323204e-05 -0.000473 -0.686917  0.723464 -0.065812 -0.020336 -0.083333  0.153846     0.96 -0.042940 -0.044987 -0.195756\n23076     B2      1           L  1716.86400  0.170708  0.275335 -0.429827  0.124533 -0.000892  0.034823 -0.001100  8.536420e-05 -0.000707 -0.687422  0.724372 -0.051794 -0.007331  0.041667  0.115385     1.00  0.092206 -0.011765 -0.173028\n23077     B2      1           L  1733.53800  0.155890  0.277158 -0.437038  0.109715  0.000932  0.027611 -0.000889  1.093649e-04 -0.000432 -0.684852  0.727940 -0.031998  0.007577  0.291667 -0.230769     1.04  0.356445  0.033651  0.156323\n23078     B2      1           L  1750.20000  0.139727  0.277694 -0.447256  0.093551  0.001467  0.017394 -0.000970  3.213831e-05 -0.000613 -0.681714  0.731013 -0.008207  0.028616  0.333333 -0.384615     1.00  0.375378  0.006285  0.324842\n23079     B2      1           L  1766.89800  0.122326  0.280266 -0.456208  0.076150  0.004040  0.008441 -0.001042  1.540715e-04 -0.000536 -0.680415  0.730912  0.014951  0.050792  0.375000 -0.384615     0.96  0.389654 -0.033088  0.351291\n23080     B2      1           L  1783.54200  0.109845  0.280601 -0.462796  0.063670  0.004375  0.001854 -0.000750  2.009019e-05 -0.000396 -0.679298  0.730210  0.031150  0.066165  0.375000 -0.423077     0.92  0.363675 -0.068360  0.407194\n23081     B2      1           L  1800.20600  0.093857  0.282172 -0.472300  0.047681  0.005945 -0.007650 -0.000959  9.425929e-05 -0.000570 -0.678641  0.729879  0.038300  0.072493  0.416667 -0.461539     0.96  0.391533 -0.026287  0.454767\n23082     B2      1           L  1816.87800  0.077229  0.283390 -0.480999  0.031053  0.007164 -0.016349 -0.000997  7.310435e-05 -0.000522 -0.675073  0.729482  0.062940  0.090388  0.500000 -0.423077     1.00  0.444282  0.015294  0.448092\n23083     B2      1           L  1833.54700  0.063921  0.283913 -0.486775  0.017746  0.007687 -0.022125 -0.000798  3.134871e-05 -0.000347 -0.672427  0.730339  0.073020  0.095476  0.666667 -0.423077     1.08  0.592515  0.097308  0.484438\n23084     B2      1           L  1850.21100  0.051641  0.284432 -0.492428  0.005465  0.008206 -0.027779 -0.000737  3.114196e-05 -0.000339 -0.668117  0.732585  0.084283  0.099175  0.791667 -0.423077     1.16  0.694450  0.187132  0.509695\n23085     B2      1           L  1866.88300  0.040971  0.284699 -0.495705 -0.005205  0.008472 -0.031055 -0.000640  1.599694e-05 -0.000197 -0.667312  0.732845  0.087042  0.100286  0.750000 -0.384615     1.12  0.657521  0.146538  0.466846\n23086     B2      1           L  1883.55200  0.029840  0.285829 -0.498527 -0.016336  0.009603 -0.033878 -0.000668  6.782150e-05 -0.000169 -0.668266  0.731234  0.090907  0.102244  0.500000 -0.192308     1.08  0.459706  0.091095  0.227076\n23087     B2      1           L  1900.21600  0.021282  0.286547 -0.498999 -0.024894  0.010321 -0.034350 -0.000514  4.309047e-05 -0.000028 -0.673125  0.726405  0.093878  0.102106  0.291667  0.000000     0.96  0.301523 -0.043103  0.010092\n"
     ]
    }
   ],
   "source": [
    "print(grouped.keys(), '\\n')\n",
    "print(grouped.__len__(), '\\n')\n",
    "print(grouped[1, 'B2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# hyperparams\n",
    "\n",
    "num_epoch = 100\n",
    "total_series_length = 50000\n",
    "truncated_backprop_length = 15\n",
    "state_size = 4 # number of layers\n",
    "number_classes = 2\n",
    "echo_step = 3\n",
    "batch_size = 5\n",
    "number_classes = total_series_length // batch_size // truncated_backprop_length\n",
    "timestep = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = tf.placeholder(tf.float32, [timestep, batch_size])\n",
    "\n",
    "def batch_poducer(raw_data, batch_size, num_steps):\n",
    "    \n",
    "    \n",
    "    \n",
    "    raw_data = tf.convert_to_tensor(raw_data, name='raw_data', dtype= tf.float32)\n",
    "    data_len = tf.size(raw_data)\n",
    "    batch_len = data_len // batch_size\n",
    "    \n",
    "    data = tf.reshape(raw_data[0:batch_size * batch_len],\n",
    "                      [batch_size, batch_len])\n",
    "    \n",
    "    epoch_size = (batch_len -1) // num_steps\n",
    "    \n",
    "    i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()\n",
    "    x = data[:, i * num_steps: (i + 1) * num_steps]\n",
    "    x.set_shape([batch_size, num_steps])\n",
    "    \n",
    "    y = data[:, i * num_steps + 1: (i + 1) * num_steps]\n",
    "    y.set_Shape([batch_size, num_steps])\n",
    "    \n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatedData():\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    # shift 4 steps to the left\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0: echo_step] = 0\n",
    "    x = x.reshape(((batch_size, -1)))\n",
    "    y = y.reshape((batch_size, -1))\n",
    "    return(x,y)\n",
    "data = generatedData()\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "init_state = tf.placeholder(tf.float32, [batch_size, state_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weights and biasses\n",
    "w = tf.Variable(np.random.rand(state_size + 1, state_size), dtype=tf.float32)\n",
    "b = tf.Variable(np.zeros((1, state_size)), dtype=tf.float32)\n",
    "\n",
    "# second set\n",
    "w2 = tf.Variable(np.random.rand(state_size, number_classes), dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1, number_classes)), dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unpack matrix into 1 dimensional array\n",
    "input_series = tf.unstack(batchX_placeholder, axis=1)\n",
    "labels_series = tf.unstack(batchY_placeholder, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forward pass\n",
    "# state placeholder\n",
    "current_state = init_state\n",
    "state_series = []\n",
    "\n",
    "for current_input in input_series:\n",
    "    current_input = tf.reshape(current_input, [batch_size, 1])\n",
    "    input_and_state_concatenated = tf.concat(axis=1, values=[current_input, current_state])\n",
    "    \n",
    "    next_state = tf.tanh(tf.matmul(input_and_state_concatenated, w) + b)\n",
    "    state_series.append(next_state)\n",
    "    current_state = next_state #forward pass and give hidden state and save to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate loss and minimise it\n",
    "logits_series = [tf.matmul(state, w2) + b2 for state in state_series]\n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "\n",
    "# cross entropy measures the difference the two probability distributions which is our loss\n",
    "# we want to minimise the difference between teh output probability and our sequence\n",
    "# machine learning is about losses and optimisation\n",
    "\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)for logits, labels in zip(logits_series, labels_series)]\n",
    "\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "# similar to stochastic gradient decent\n",
    "# an optimastion tool\n",
    "# but the learning rate is adaptable\n",
    "# weights that receive high gradient have their effective learning rate reduced \n",
    "# weights that have low gradients will have their effective learning rate increased\n",
    "# 0.3 the learning rate\n",
    "#print(tf.trainable_variables())\n",
    "optimiser = tf.train.AdagradOptimizer(0.3)\n",
    "\n",
    "train_step = optimiser.minimize(total_loss)\n",
    "#tran_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visualizer\n",
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 Loss 6.3818107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 1\nStep 0 Loss 2.451775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 2\nStep 0 Loss 1.3581579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 3\nStep 0 Loss 1.0493375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 4\nStep 0 Loss 0.94657063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 5\nStep 0 Loss 0.8853234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 6\nStep 0 Loss 0.83895314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 7\nStep 0 Loss 0.76545006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 8\nStep 0 Loss 0.78922534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 9\nStep 0 Loss 0.770537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 10\nStep 0 Loss 0.785698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 11\nStep 0 Loss 0.7505636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 12\nStep 0 Loss 0.74360186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 13\nStep 0 Loss 0.74018174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 14\nStep 0 Loss 0.73995805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 15\nStep 0 Loss 0.7621933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 16\nStep 0 Loss 0.72313535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 17\nStep 0 Loss 0.7126708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 18\nStep 0 Loss 0.7388106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 19\nStep 0 Loss 0.71820873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 20\nStep 0 Loss 0.7254051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 21\nStep 0 Loss 0.723003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 22\nStep 0 Loss 0.7229673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 23\nStep 0 Loss 0.72404706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 24\nStep 0 Loss 0.73066044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 25\nStep 0 Loss 0.71741426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 26\nStep 0 Loss 0.71307474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 27\nStep 0 Loss 0.6985569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 28\nStep 0 Loss 0.71837455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 29\nStep 0 Loss 0.71799463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 30\nStep 0 Loss 0.7149093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 31\nStep 0 Loss 0.7090983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 32\nStep 0 Loss 0.69387054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 33\nStep 0 Loss 0.704575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 34\nStep 0 Loss 0.70961404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 35\nStep 0 Loss 0.70751864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 36\nStep 0 Loss 0.71644634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 37\nStep 0 Loss 0.70985144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 38\nStep 0 Loss 0.70404446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 39\nStep 0 Loss 0.7063564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 40\nStep 0 Loss 0.7155037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 41\nStep 0 Loss 0.70446897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 42\nStep 0 Loss 0.7063158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 43\nStep 0 Loss 0.70593935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 44\nStep 0 Loss 0.6997627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 45\nStep 0 Loss 0.7016429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 46\nStep 0 Loss 0.72167176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 47\nStep 0 Loss 0.69964707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 48\nStep 0 Loss 0.70787966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 49\nStep 0 Loss 0.7185914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 50\nStep 0 Loss 0.71011615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 51\nStep 0 Loss 0.70429057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 52\nStep 0 Loss 0.70157224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 53\nStep 0 Loss 0.70569813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 54\nStep 0 Loss 0.70182586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 55\nStep 0 Loss 0.7248377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 56\nStep 0 Loss 0.703737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 57\nStep 0 Loss 0.7003072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 58\nStep 0 Loss 0.6982054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 59\nStep 0 Loss 0.6979473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 60\nStep 0 Loss 0.6984007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 61\nStep 0 Loss 0.69972795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 62\nStep 0 Loss 0.7024007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 63\nStep 0 Loss 0.6983271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 64\nStep 0 Loss 0.70978075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 65\nStep 0 Loss 0.69789624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 66\nStep 0 Loss 0.70191556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 67\nStep 0 Loss 0.70282483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 68\nStep 0 Loss 0.70079374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 69\nStep 0 Loss 0.7047681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 70\nStep 0 Loss 0.70370847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 71\nStep 0 Loss 0.70245534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 72\nStep 0 Loss 0.6994609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 73\nStep 0 Loss 0.69862247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 74\nStep 0 Loss 0.6973578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 75\nStep 0 Loss 0.7019153\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_qt5agg.py\u001b[0m in \u001b[0;36mpaintEvent\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bbox_queue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mpaintEvent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \"\"\"Copy the image from the Agg canvas to the qt.drawable.\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 76\nStep 0 Loss 0.7020657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 77\nStep 0 Loss 0.699161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 78\nStep 0 Loss 0.70034516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 79\nStep 0 Loss 0.7002878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 80\nStep 0 Loss 0.7531312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 81\nStep 0 Loss 0.6995826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 82\nStep 0 Loss 0.7000177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 83\nStep 0 Loss 0.69725436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 84\nStep 0 Loss 0.69415736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 85\nStep 0 Loss 0.7089903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 86\nStep 0 Loss 0.7005602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 87\nStep 0 Loss 0.7036839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 88\nStep 0 Loss 0.70399046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 89\nStep 0 Loss 0.70650464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 90\nStep 0 Loss 0.7073554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 91\nStep 0 Loss 0.69612867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 92\nStep 0 Loss 0.69878125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 93\nStep 0 Loss 0.70192564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 94\nStep 0 Loss 0.70514435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 95\nStep 0 Loss 0.6976769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 96\nStep 0 Loss 0.69660085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 97\nStep 0 Loss 0.70367527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 98\nStep 0 Loss 0.69716614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 99\nStep 0 Loss 0.69630873\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################################################################\n",
    "#Step 3 Training the network\n",
    "with tf.Session() as sess:\n",
    "    #we stupidly have to do this everytime, it should just know\n",
    "    #that we initialized these vars. v2 guys, v2..\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    #interactive mode\n",
    "    plt.ion()\n",
    "    #initialize the figure\n",
    "    plt.figure()\n",
    "    #show the graph\n",
    "    plt.show()\n",
    "    #to show the loss decrease\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epoch):\n",
    "        #generate data at eveery epoch, batches run in epochs\n",
    "        x,y = generatedData()\n",
    "        #initialize an empty hidden state\n",
    "        _current_state = np.zeros((batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "        #each batch\n",
    "        for batch_idx in range(batch_size):\n",
    "            #starting and ending point per batch\n",
    "            #since weights reoccuer at every layer through time\n",
    "            #These layers will not be unrolled to the beginning of time, \n",
    "            #that would be too computationally expensive, and are therefore truncated \n",
    "            #at a limited number of time-steps\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "            \n",
    "            #run the computation graph, give it the values\n",
    "            #we calculated earlier\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder:batchX,\n",
    "                    batchY_placeholder:batchY,\n",
    "                    init_state:_current_state\n",
    "                })\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 Loss 6.124838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 1\nStep 0 Loss 2.3611636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 2\nStep 0 Loss 1.2596455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 3\nStep 0 Loss 1.0324018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 4\nStep 0 Loss 0.9322508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 5\nStep 0 Loss 0.86537313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 6\nStep 0 Loss 0.80125517\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mrgba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_colors_full_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Not in cache, or unhashable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-228-cb2f3869f841>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Step\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_total_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_predictions_series\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mioff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-223-aaf79cd4affa>\u001b[0m in \u001b[0;36mplot\u001b[1;34m(loss_list, predictions_series, batchX, batchY)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_series_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"blue\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_series_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"red\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msingle_output_series\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"green\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2625\u001b[0m                       mplDeprecation)\n\u001b[0;32m   2626\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2627\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2628\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2629\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1708\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[0;32m   1709\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1710\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1711\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2146\u001b[0m                 \u001b[0medgecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2147\u001b[0m                 \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2148\u001b[1;33m                 \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_nolegend_'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2149\u001b[0m                 )\n\u001b[0;32m   2150\u001b[0m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, xy, width, height, angle, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m         \"\"\"\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m         \u001b[0mPatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, edgecolor, facecolor, color, linewidth, linestyle, antialiased, hatch, fill, capstyle, joinstyle, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_linewidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_linestyle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinestyle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_linewidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36mset_fill\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    441\u001b[0m         \"\"\"\n\u001b[0;32m    442\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fill\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_facecolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_facecolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_edgecolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_edgecolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36m_set_facecolor\u001b[1;34m(self, color)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'patch.facecolor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alpha\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fill\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_facecolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mrgba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_colors_full_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Not in cache, or unhashable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[0mrgba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0m_colors_full_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrgba\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid RGBA argument: {!r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Return a tuple to prevent the cached value from being modified.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RGBA sequence should have length 3 or 4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
